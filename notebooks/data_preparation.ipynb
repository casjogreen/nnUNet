{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import json, os, logging, random, copy, shutil\n",
    "import seaborn as sns, pandas as pd, numpy as np, nibabel as nib\n",
    "from ipywidgets import interact, IntSlider, Select, HBox\n",
    "from utilities import apply_windowing, resize_to_user_resolution\n",
    "from dicom_tools import DicomToolbox   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get environment variables\n",
    "import os\n",
    "\n",
    "# Replace 'YOUR_ENV_VAR' with the name of your environment variable\n",
    "env_var_value = os.getenv('nnUNet_raw')\n",
    "\n",
    "print(env_var_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(dt.ct.data[dt.ct.data.shape[0]//2], cmap='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.dose.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06187a53762942f0a6864870a7039eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 294\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m contours\n\u001b[1;32m    293\u001b[0m dp \u001b[38;5;241m=\u001b[39m Preprocessing(params)\n\u001b[0;32m--> 294\u001b[0m \u001b[43mdp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_insight_file_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/ivazquez/Repos/nnUNet/raw_data/data_insight_Dataset001_NeckCTA.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 159\u001b[0m, in \u001b[0;36mPreprocessing.prepare_data\u001b[0;34m(self, data_insight_file_path)\u001b[0m\n\u001b[1;32m    156\u001b[0m                 mask, _ \u001b[38;5;241m=\u001b[39m resize_to_user_resolution(contour[contour_name]\u001b[38;5;241m.\u001b[39mdata, orig_coords, new_res, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRESAMPLING\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m (contour[label]\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    157\u001b[0m                 f\u001b[38;5;241m.\u001b[39mcreate_dataset(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mround(mask)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8))\n\u001b[0;32m--> 159\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_data_breakdowns\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessed_data_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 186\u001b[0m, in \u001b[0;36mPreprocessing.create_data_breakdowns\u001b[0;34m(self, data_path)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_data_breakdowns\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_path):\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    187\u001b[0m         all_data_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(f\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLEAVE_OUT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: all_data_ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(pat) \u001b[38;5;28;01mfor\u001b[39;00m pat \u001b[38;5;129;01min\u001b[39;00m all_data_ids \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mint\u001b[39m(pat) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLEAVE_OUT\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m~/Tools/miniconda3/envs/mlenv/lib/python3.11/site-packages/h5py/_hl/files.py:537\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    535\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrepr\u001b[39m(name)\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mASCII\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[43mfilename_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m track_order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m     track_order \u001b[38;5;241m=\u001b[39m h5\u001b[38;5;241m.\u001b[39mget_config()\u001b[38;5;241m.\u001b[39mtrack_order\n",
      "File \u001b[0;32m~/Tools/miniconda3/envs/mlenv/lib/python3.11/site-packages/h5py/_hl/compat.py:19\u001b[0m, in \u001b[0;36mfilename_encode\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilename_encode\u001b[39m(filename):\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    Encode filename for use in the HDF5 library.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    filenames in h5py for more information.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fspath(filename)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filename, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from dicom_tools import DicomTools   \n",
    "import logging, os, json, random, copy, shutil, h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns, pandas as pd, numpy as np, nibabel as nib\n",
    "from ipywidgets import interact, IntSlider, Select, HBox\n",
    "from utilities import apply_windowing, resize_to_user_resolution\n",
    "\n",
    "params = {\n",
    "    'DATA_DIRECTORY':  \"/home/ivazquez/Data/anonymized/neck_cta\", #, \"/home/ivazquez/Documents/Data/liver\",\n",
    "    'PREPROCESSED_DATA_DIRECTORY': \"/home/ivazquez/Repos/nnUNet/raw_data/preprocessed_hdf5_files/preprocessed_Dataset001_NeckCTA.h5\",\n",
    "    'RESAMPLING': {'apply': True, 'resolution': (1.0, 1.0, 1.0)},\n",
    "    'LABELS': [\"common_carotid_artery_left\"],\n",
    "    'DATASET_DESCRIPTION': {\n",
    "        'id': 1,\n",
    "        'name': 'NeckCTA',\n",
    "        'description': 'Neck CTA dataset',\n",
    "        'reference': 'HMH'\n",
    "    },\n",
    "    'TEST_SET_SIZE': 2,\n",
    "    'LEAVE_OUT': None,\n",
    "    'INPUT_MODALITIES': ['ct'],\n",
    "    'OUTPUT_MODALITIES': ['rtstruct']}\n",
    "\n",
    "\n",
    "# params = {\n",
    "#     'DATA_DIRECTORY': \"/home/ivazquez/Documents/Data/liver\", #\"../raw_data/neck_cta/anonymized\", #\"/home/ivazquez/Data/anonymized/neck_cta\" ,\n",
    "#     'PREPROCESSED_DATA_DIRECTORY': \"/home/ivazquez/Documents/Data/nnunet_raw/preprocessed_hdf5_files/preprocessed_Dataset001_Liver.h5\",\n",
    "#     'RESAMPLING': {'apply': True, 'resolution': (1.5, 1.5, 1.5)},\n",
    "#     'LABELS': [\"liver\"],\n",
    "#     'DATASET_DESCRIPTION': {\n",
    "#         'id': 1,\n",
    "#         'name': 'Liver',\n",
    "#         'description': 'Liver dataset',\n",
    "#         'reference': 'MDA'\n",
    "#     },\n",
    "#     'TEST_SET_SIZE': 2,\n",
    "#     'LEAVE_OUT': None,\n",
    "#     'INPUT_MODALITIES': ['ct'],\n",
    "#     'OUTPUT_MODALITIES': ['rtstruct']}\n",
    "\n",
    "class Preprocessing(DicomTools):\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        self.__start_logger()\n",
    "        self.params = params\n",
    "        super().__init__(patient_data_directory=params['DATA_DIRECTORY'])\n",
    "        self.expected_data = params['INPUT_MODALITIES'] + params['OUTPUT_MODALITIES']\n",
    "        self.labels = params['LABELS']\n",
    "        self.echo_level = 0\n",
    "        self.minimum_ct_value = -1024\n",
    "        self.uniform_slice_thickness = False # forces uniform slice thickness for CT during parsing\n",
    "        self.preprocessed_data_dir = params['PREPROCESSED_DATA_DIRECTORY']\n",
    "        self.raw_data_dir = os.getenv('nnUNet_raw') # assumet that nnUNet environment variable is set and defined as nnUNet_raw\n",
    "        self.__data_id = f'Dataset{params[\"DATASET_DESCRIPTION\"][\"id\"]:03}_{params[\"DATASET_DESCRIPTION\"][\"name\"]}'\n",
    "        self.__default_data_insight_path = os.path.join(self.raw_data_dir, )\n",
    "        \n",
    "    def __start_logger(self):\n",
    "        if not os.path.exists('logs'):\n",
    "            os.makedirs('logs')\n",
    "        log_file = os.path.join('logs','data_preparation.log')\n",
    "        with open(log_file, 'w') as f:\n",
    "            pass\n",
    "        logging.basicConfig(filename=log_file, filemode='w',\n",
    "                            level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "        \n",
    "    def get_data_insight(self):\n",
    "        all_pat_ids = self.identify_patient_files()\n",
    "        self.data_insight = {p:{} for p in all_pat_ids}\n",
    "        \n",
    "        progress_bar = tqdm(all_pat_ids, desc=\"\")\n",
    "        \n",
    "        for p in progress_bar:\n",
    "            \n",
    "            try:\n",
    "                progress_bar.set_description(f'Getting data insight for pat-{p}')\n",
    "                \n",
    "                self.reset()\n",
    "                \n",
    "                self.run_initial_check(p)\n",
    "                \n",
    "                self.ct = self.parse_ct_study_files(self.dicom_files['ct'])\n",
    "                \n",
    "                self.contours = self.parse_structure_files(files=self.dicom_files['structures'], names_only=True)\n",
    "\n",
    "                self.data_insight[p]['input_modalities'] = {m:0 for m in self.params['INPUT_MODALITIES']}\n",
    "                \n",
    "                #TODO: Currently assumes that CT is always present - starting test with CT - more will be added later\n",
    "                \n",
    "                self.data_insight[p]['input_modalities']['ct']={'shape': [i for i in self.ct.data.shape], \n",
    "                                                                'min': self.ct.data.min(),\n",
    "                                                                'max': self.ct.data.max(),\n",
    "                                                                'dx': self.ct.coordinates.dx,\n",
    "                                                                'dy': self.ct.coordinates.dy,\n",
    "                                                                'dz': [i for i in self.ct.coordinates.dz],\n",
    "                                                                'position':self.ct.patient_position}\n",
    "                self.data_insight[p]['labels'] = self.find_structures(p, contours = self.labels)\n",
    "                self.data_insight[p]['number_of_structures'] = len(self.contours)\n",
    "                self.data_insight[p]['structures_available'] = [c for c in self.contours]\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error in patient {p}: {e}\")\n",
    "                self.data_insight[p]['error'] = str(e)\n",
    "                    \n",
    "        with open(os.path.join(self.raw_data_dir,f'data_insight_{self.__data_id}.json'), 'w') as f:\n",
    "            json.dump(self.data_insight, f, indent=4)\n",
    "    \n",
    "    def prepare_data(self, data_insight_file_path= None):\n",
    "        \n",
    "        self.prepare_dataset_folders() # create dataset folders\n",
    "        \n",
    "        if data_insight_file_path is not None:\n",
    "            self.data_insight = json.load(open(data_insight_file_path, 'r'))\n",
    "        else:\n",
    "            self.get_data_insight()\n",
    "            \n",
    "        parent_dir = os.path.join(self.raw_data_dir, 'preprocessed_hdf5_files')\n",
    "        if not os.path.exists(parent_dir): os.makedirs(parent_dir)\n",
    "            \n",
    "        if self.preprocessed_data_dir is not None and os.path.exists(self.preprocessed_data_dir):\n",
    "            preprocess_data = False\n",
    "        elif self.preprocessed_data_dir is not None and not os.path.exists(self.preprocessed_data_dir):\n",
    "            preprocess_data = True\n",
    "        else:\n",
    "            preprocess_data = True\n",
    "            self.preprocessed_data_dir = os.path.join(parent_dir, f'preprocessed_{self.__data_id}.h5')\n",
    "    \n",
    "        if preprocess_data:\n",
    "                        \n",
    "            if not os.path.exists(parent_dir): \n",
    "                os.makedirs(parent_dir)\n",
    "            \n",
    "            with h5py.File(self.preprocessed_data_dir, 'w') as f:\n",
    "                \n",
    "                progress_bar = tqdm([p for p in self.data_insight], desc=\"\")\n",
    "                \n",
    "                for p in progress_bar:\n",
    "                    \n",
    "                    progress_bar.set_description(f'Preprocessing data for pat-{p}')\n",
    "                    \n",
    "                    patient_info = self.data_insight[p]\n",
    "                    if 'error' in patient_info: continue \n",
    "                    if not all([patient_info['labels'][l] for l in patient_info['labels']]): continue\n",
    "                                    \n",
    "                    self.reset()\n",
    "                    self.run_initial_check(p)  \n",
    "                    self.ct = self.parse_ct_study_files(self.dicom_files['ct'])  \n",
    "                    \n",
    "                    # resample data here\n",
    "                    orig_coords = copy.deepcopy(self.ct.coordinates) \n",
    "                    new_res = self.params['RESAMPLING']['resolution']\n",
    "                    \n",
    "                    ct, coords = resize_to_user_resolution(self.ct.data, orig_coords, new_res, fill_value=self.ct.data.min()) if self.params['RESAMPLING']['apply'] else (self.ct.data, orig_coords)\n",
    "                \n",
    "                    f.create_dataset(f'{p}/ct', data=ct, compression='lzf')\n",
    "                    f.create_dataset(f'{p}/coordinates/x', data=coords.x)\n",
    "                    f.create_dataset(f'{p}/coordinates/y', data=coords.y)\n",
    "                    f.create_dataset(f'{p}/coordinates/z', data=coords.z)\n",
    "                    f.create_dataset(f'{p}/coordinates/dx', data=coords.dx)\n",
    "                    f.create_dataset(f'{p}/coordinates/dy', data=coords.dy)\n",
    "                    f.create_dataset(f'{p}/coordinates/dz', data=coords.dz)\n",
    "                                    \n",
    "                    for label in self.labels:\n",
    "                        contour_name = patient_info['labels'][label]\n",
    "                        contour = self.parse_structure_files(files=sorted(self.dicom_files['structures']), patient_id=p, mask_names=contour_name, resolution='ct')\n",
    "                        mask, _ = resize_to_user_resolution(contour[contour_name].data, orig_coords, new_res, fill_value=0) if self.params['RESAMPLING']['apply'] else (contour[label].data, None)\n",
    "                        f.create_dataset(f'{p}/{label}', data=np.round(mask).astype(np.uint8))\n",
    "        \n",
    "        self.create_data_breakdowns(self.preprocessed_data_dir)\n",
    "                        \n",
    "    def save_as_nifti(self, volume, voxel_spacing, output_path):\n",
    "        \n",
    "        if not isinstance(voxel_spacing, (list, tuple)) or len(voxel_spacing) != 3:\n",
    "            raise ValueError(\"voxel_spacing must be a list or tuple with 3 elements.\")\n",
    "\n",
    "        affine = np.eye(4)\n",
    "        affine[0, 0] = voxel_spacing[0]  # Spacing in x\n",
    "        affine[1, 1] = voxel_spacing[1]  # Spacing in y\n",
    "        affine[2, 2] = voxel_spacing[2]  # Spacing in z\n",
    "\n",
    "        nifti_image = nib.Nifti1Image(volume, affine=affine)\n",
    "\n",
    "        nib.save(nifti_image, output_path)       \n",
    "    \n",
    "    def prepare_dataset_folders(self):\n",
    "        \n",
    "        self.dataset_path = os.path.join(self.raw_data_dir, self.__data_id) # depends on the nnUNet environment variable\n",
    "        if os.path.exists(self.dataset_path ): shutil.rmtree(self.dataset_path )\n",
    "        os.makedirs(self.dataset_path , exist_ok=True)  \n",
    "        \n",
    "        for dir_name in ['imagesTr', 'imagesTs', 'labelsTr', 'labelsTs']:\n",
    "            os.makedirs(os.path.join(self.dataset_path , dir_name), exist_ok=True)\n",
    "    \n",
    "    def create_data_breakdowns(self, data_path):\n",
    "        \n",
    "        with h5py.File(data_path, 'r') as f:\n",
    "            all_data_ids = list(f.keys())\n",
    "        \n",
    "        if self.params['LEAVE_OUT'] is not None: all_data_ids = [int(pat) for pat in all_data_ids if int(pat) not in self.params['LEAVE_OUT']]\n",
    "\n",
    "        self.test_set = random.sample(all_data_ids, self.params['TEST_SET_SIZE'])\n",
    "        self.train_set = [n for n in all_data_ids if n not in self.test_set]\n",
    "        \n",
    "        # save training data\n",
    "        with h5py.File(data_path, 'r') as f:\n",
    "            \n",
    "            progress_bar = tqdm(self.train_set, desc=\"Saving training data:\")\n",
    "            \n",
    "            for n,pat in enumerate(progress_bar):\n",
    "                ct = f[f'{pat}/ct'][:]\n",
    "                voxel_spacing = [f[f'{pat}/coordinates/dx'][()], f[f'{pat}/coordinates/dy'][()], f[f'{pat}/coordinates/dz'][()]]\n",
    "                output_path = os.path.join(self.dataset_path, 'imagesTr',  f\"TrDat{n:03}_0000.nii.gz\")\n",
    "                self.save_as_nifti( np.transpose(ct, (2, 1, 0)), voxel_spacing,  output_path) # TODO: addapt to other modalities later\n",
    "            \n",
    "                label_data = np.sum([f[f'{pat}/{l}'][:] for l in self.labels], axis=0)\n",
    "                output_path = os.path.join(self.dataset_path, 'labelsTr',  f\"TrDat{n:03}.nii.gz\")\n",
    "                self.save_as_nifti(np.transpose(label_data, (2, 1, 0)).astype(np.uint8), voxel_spacing,  output_path)\n",
    "            \n",
    "            progress_bar = tqdm(self.test_set, desc=\"Saving test data:\")\n",
    "            \n",
    "            for n,pat in enumerate(progress_bar):\n",
    "                ct = f[f'{pat}/ct'][:]\n",
    "                voxel_spacing = [f[f'{pat}/coordinates/dx'][()], f[f'{pat}/coordinates/dy'][()], f[f'{pat}/coordinates/dz'][()]]\n",
    "                output_path = os.path.join(self.dataset_path, 'imagesTs',  f\"TsDat{n:03}_0000.nii.gz\")\n",
    "                self.save_as_nifti( np.transpose(ct, (2, 1, 0)), voxel_spacing,  output_path)\n",
    "                \n",
    "                label_data = np.sum([f[f'{pat}/{l}'][:] for l in self.labels], axis=0)\n",
    "                output_path = os.path.join(self.dataset_path, 'labelsTs',  f\"TsDat{n:03}.nii.gz\")\n",
    "                self.save_as_nifti( np.transpose(label_data, (2, 1, 0)).astype(np.uint8), voxel_spacing,  output_path)\n",
    "    \n",
    "    # def __save_dataset(self, hf, id, dataset): # TODO: finish this function to remove redundancy above\n",
    "    #     ct = hf[f'{id}/ct'][:]\n",
    "    #     voxel_spacing = [hf[f'{id}/coordinates/dx'][()], hf[f'{id}/coordinates/dy'][()], hf[f'{id}/coordinates/dz'][()]]\n",
    "    #     dataset_name = {}\n",
    "    #     output_path = os.path.join(self.dataset_path, dataset,  f\"TrDat{id:03}_0000.nii.gz\")\n",
    "                \n",
    "    def find_structures(self, pat_id, contours = [], desperate_mode = True):\n",
    "                      \n",
    "        # prepare dictionary with desired contours\n",
    "        assert type(contours) == type([]) or type(contours) == type(()), \"Contours must be a list or tuple\"\n",
    "        contours = {c:0 for c in self.labels} if contours == [] else {c:0 for c in contours}\n",
    "                \n",
    "        # Load the variations for contour names\n",
    "        with open(os.path.join(\"assets\", \"structure_name_variations.json\"),\"r\") as f:\n",
    "            contour_variations = json.load(f)\n",
    "        \n",
    "        # items added to the name of contours that make it difficult to identify them\n",
    "        with open(os.path.join(\"assets\", \"junk_symbols.json\"),\"r\") as f:\n",
    "            junk_symbols = json.load(f)['oar']\n",
    "\n",
    "        # Grab available contours for current patients\n",
    "        if hasattr(self, 'contours'):\n",
    "            available_contours = self.contours if type(self.contours) == type([]) else self.contour.keys() \n",
    "        else:\n",
    "            self.run_initial_check(pat_id)\n",
    "            self.parse_structure_files(names_only = True)\n",
    "            available_contours = self.contours\n",
    "        \n",
    "        lr_variations = contour_variations[\"sides\"] # variations for left and right\n",
    "        links = ['_','-',\" \",\"\"] # types of links used for word elements in contour names\n",
    "                \n",
    "        for c in contours:  \n",
    "\n",
    "            side = lr_variations[\"left\"]  if \"left\" in c else lr_variations[\"right\"]  if \"right\" in c else [\"\"]\n",
    "            gland = contour_variations[\"gland\"] + [\"\"] if 'gland' in c else [\"\"] \n",
    "            links2 = links if 'gland' in c else [\"\"] # links to attach gland to name \n",
    "            k = '_'.join([kk for kk in c.split('_') if kk not in ['left', 'right', 'gland']]) \n",
    "              \n",
    "            # generate name variations\n",
    "            name_variations = [f\"{n}{l1}{g}{l2}{s}\" for n in contour_variations[k] for l1 in links for l2 in links2 for s in side for g in gland]\n",
    "            name_variations += [f\"{g}{l1}{n}{l2}{s}\" for n in contour_variations[k] for l1 in links for l2 in links2 for s in side for g in gland]\n",
    "            name_variations += [f\"{s}{l1}{n}{l2}{g}\" for n in contour_variations[k] for l1 in links for l2 in links2 for s in side for g in gland]\n",
    "            name_variations += [f\"{s}{l1}{g}{l2}{n}\" for n in contour_variations[k] for l1 in links for l2 in links2 for s in side for g in gland]\n",
    "                            \n",
    "            for v in name_variations:\n",
    "\n",
    "                if contours[c] != 0: break\n",
    "\n",
    "                for n in available_contours:\n",
    "                    if n == v: contours[c] = n.strip()\n",
    "\n",
    "                for n in available_contours:\n",
    "                    if contours[c] == 0:\n",
    "                        n_new = \"\".join([i for i in n if not i.isdigit()])\n",
    "                        if n_new.strip() == v: contours[c] = n.strip()\n",
    "\n",
    "                for n in available_contours:\n",
    "                    if contours[c] == 0:\n",
    "                        n_new = \"\".join([i for i in n.strip() if i not in ['_','/','.','-']])\n",
    "                        n_new = \"\".join([i for i in n_new if not i.isdigit()])\n",
    "                        if n_new.strip() == v: contours[c]= n.strip()\n",
    "                        \n",
    "                for n in available_contours:\n",
    "                    if desperate_mode and contours[c] == 0:\n",
    "                        for item in junk_symbols:\n",
    "                            n_new = n.strip().replace(item,\"\")\n",
    "                            n_new = \"\".join([i for i in n_new.strip() if i not in ['_','/','.','-']])\n",
    "                            n_new = \"\".join([i for i in n_new if not i.isdigit()])\n",
    "                            if n_new.strip() == v: contours[c] = n.strip()    \n",
    "                               \n",
    "        return contours\n",
    "        \n",
    "dp = Preprocessing(params)\n",
    "dp.prepare_data(data_insight_file_path = \"/home/ivazquez/Repos/nnUNet/raw_data/data_insight_Dataset001_NeckCTA.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File('../raw_data/preprocessed_hdf5_files/preprocessed_Dataset001_NeckCTA.h5', 'r') as f:\n",
    "    print(f.keys())\n",
    "    print(f['1'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_integer = next((x for x in range(1, max(np.arange(100))+2) if x not in [1,2,3]), 1)\n",
    "starting_integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'data' is your 3D numpy array with shape (z, y, x)\n",
    "data_transposed = np.transpose(data, (2, 1, 0))\n",
    "\n",
    "# Now, 'data_transposed' is your data with shape (x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def process_items(items):\n",
    "    progress_bar = tqdm(items, desc='Starting')\n",
    "    for item in progress_bar:\n",
    "        # Simulate processing\n",
    "        time.sleep(0.5)\n",
    "        # Update the description with the current item being processed\n",
    "        progress_bar.set_description(f'Processing {item}')\n",
    "        \n",
    "process_items(range(1, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_pat_ids = [int(pat) for pat in all_pat_ids if int(pat) not in LEAVE_OUT]\n",
    "\n",
    "# Randomly select test set\n",
    "test_set = random.sample(all_pat_ids, TEST_SET_SIZE)\n",
    "train_set = [pat for pat in all_pat_ids if pat not in test_set]\n",
    "\n",
    "# Prepare output directories\n",
    "output_dir = os.path.join(os.path.dirname(DATA_DIRECTORY), 'preprocessed')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"Created output directory: {output_dir}\")\n",
    "    \n",
    "for dir_name in ['imagesTr', 'imagesTs', 'labelsTr', 'labelsTs']:\n",
    "    if os.path.exists(os.path.join(output_dir, dir_name)): shutil.rmtree(os.path.join(output_dir, dir_name))\n",
    "    os.makedirs(os.path.join(output_dir, dir_name), exist_ok=True)\n",
    "\n",
    "def save_as_nifti(array_data, voxel_spacing, file_name):\n",
    "\n",
    "    if not isinstance(voxel_spacing, (list, tuple)) or len(voxel_spacing) != 3:\n",
    "        raise ValueError(\"voxel_spacing must be a list or tuple with 3 elements.\")\n",
    "\n",
    "    affine = np.eye(4)\n",
    "    affine[0, 0] = voxel_spacing[0]  # Spacing in x\n",
    "    affine[1, 1] = voxel_spacing[1]  # Spacing in y\n",
    "    affine[2, 2] = voxel_spacing[2]  # Spacing in z\n",
    "\n",
    "    # Create a NIfTI1Image object with specified voxel spacing\n",
    "    nifti_image = nib.Nifti1Image(array_data, affine=affine)\n",
    "\n",
    "    # Save the image to a NIfTI file\n",
    "    nib.save(nifti_image, f\"{file_name}.nii.gz\")\n",
    " \n",
    "def process_patients(all_pat_ids, dt, LABELS, RESAMPLING, output_dir, dataset):\n",
    "    \n",
    "    for index, pat_id in enumerate(tqdm(all_pat_ids, desc=f'Processing {dataset} patients')):\n",
    "        \n",
    "        dt.dicom_files = dt.run_initial_check(pat_id)  # Grab the dicom files\n",
    "        dt.ct = dt.parse_ct_study_files(dt.dicom_files['ct'])  # Parse the CT files\n",
    "        all_contours = dt.parse_structure_files(files=sorted(dt.dicom_files['structures']), patient_id=pat_id, names_only=True)  # Parse the structure files\n",
    "        orig_coords = copy.deepcopy(dt.ct.coordinates)  # store copy of original CT coordinates\n",
    "\n",
    "        # Resize CT if necessary\n",
    "        ct, coords = resize_to_user_resolution(dt.ct.data, orig_coords, RESAMPLING['resolution'], fill_value=dt.ct.data.min()) if RESAMPLING['apply'] else (dt.ct.data, dt.ct.coordinates)\n",
    "        \n",
    "        # Save the CT\n",
    "        if dataset == 'train':\n",
    "            save_as_nifti(ct, RESAMPLING['resolution'], os.path.join(output_dir, 'imagesTr', f\"{dataset}Patient_{index:03}_0000\"))\n",
    "        else:\n",
    "            save_as_nifti(ct, RESAMPLING['resolution'], os.path.join(output_dir, 'imagesTs', f\"{dataset}Patient_{index:03}_0000\"))\n",
    "        \n",
    "        # Prepare the labels\n",
    "        labels_dict = {}\n",
    "\n",
    "        for label in LABELS:\n",
    "            if label not in all_contours: break\n",
    "            contour = dt.parse_structure_files(files=sorted(dt.dicom_files['structures']), patient_id=pat_id, mask_names=label, resolution='ct')\n",
    "\n",
    "            # Resize the mask if necessary\n",
    "            mask, _ = resize_to_user_resolution(contour[label].data, orig_coords, RESAMPLING['resolution'], fill_value=0) if RESAMPLING['apply'] else (contour[label].data, None)\n",
    "\n",
    "            labels_dict[label] = mask\n",
    "\n",
    "        # Save the labels\n",
    "        for l in labels_dict:\n",
    "            if dataset == 'train':\n",
    "                save_as_nifti(labels_dict[l], RESAMPLING['resolution'], os.path.join(output_dir, 'labelsTr', f\"Patient_{index:03}\"))\n",
    "            else:\n",
    "                save_as_nifti(labels_dict[l], RESAMPLING['resolution'], os.path.join(output_dir, 'labelsTs', f\"patient_{index:03}\"))\n",
    "        \n",
    "process_patients(test_set, dt, LABELS, RESAMPLING, output_dir, 'test')\n",
    "process_patients(train_set, dt, LABELS, RESAMPLING, output_dir, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_contours = [dt.parse_dicom_files(pat, mask_resolution='ct', mask_names_only=True) for pat in all_pat_ids]\n",
    "\n",
    "# Assuming all_contours is a list of contour names\n",
    "unique_contours, counts = np.unique(all_contours, return_counts=True)\n",
    "\n",
    "# Printing unique contours and their counts\n",
    "for contour, count in zip(unique_contours, counts):\n",
    "    print(f\"{contour}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "from batchgenerators.utilities.file_and_folder_operations import save_json, join\n",
    "\n",
    "output_dir = '../raw_data/Dataset001_NeckCTA'\n",
    "channel_names = {0: 'CT'}\n",
    "labels = {'common_carotid_artery_left': 1,\n",
    "          'background': 0}\n",
    "num_training_cases = len(os.listdir(os.path.join(output_dir, 'imagesTr')))\n",
    "print(num_training_cases)\n",
    "file_extension = '.nii.gz'\n",
    "\n",
    "def generate_dataset_json(output_folder: str,\n",
    "                          channel_names: dict,\n",
    "                          labels: dict,\n",
    "                          num_training_cases: int,\n",
    "                          file_ending: str,\n",
    "                          regions_class_order: Tuple[int, ...] = None,\n",
    "                          dataset_name: str = None, reference: str = None, release: str = None, license: str = None,\n",
    "                          description: str = None,\n",
    "                          overwrite_image_reader_writer: str = None, **kwargs):\n",
    "    \"\"\"\n",
    "    Generates a dataset.json file in the output folder\n",
    "\n",
    "    channel_names:\n",
    "        Channel names must map the index to the name of the channel, example:\n",
    "        {\n",
    "            0: 'T1',\n",
    "            1: 'CT'\n",
    "        }\n",
    "        Note that the channel names may influence the normalization scheme!! Learn more in the documentation.\n",
    "\n",
    "    labels:\n",
    "        This will tell nnU-Net what labels to expect. Important: This will also determine whether you use region-based training or not.\n",
    "        Example regular labels:\n",
    "        {\n",
    "            'background': 0,\n",
    "            'left atrium': 1,\n",
    "            'some other label': 2\n",
    "        }\n",
    "        Example region-based training:\n",
    "        {\n",
    "            'background': 0,\n",
    "            'whole tumor': (1, 2, 3),\n",
    "            'tumor core': (2, 3),\n",
    "            'enhancing tumor': 3\n",
    "        }\n",
    "\n",
    "        Remember that nnU-Net expects consecutive values for labels! nnU-Net also expects 0 to be background!\n",
    "\n",
    "    num_training_cases: is used to double check all cases are there!\n",
    "\n",
    "    file_ending: needed for finding the files correctly. IMPORTANT! File endings must match between images and\n",
    "    segmentations!\n",
    "\n",
    "    dataset_name, reference, release, license, description: self-explanatory and not used by nnU-Net. Just for\n",
    "    completeness and as a reminder that these would be great!\n",
    "\n",
    "    overwrite_image_reader_writer: If you need a special IO class for your dataset you can derive it from\n",
    "    BaseReaderWriter, place it into nnunet.imageio and reference it here by name\n",
    "\n",
    "    kwargs: whatever you put here will be placed in the dataset.json as well\n",
    "\n",
    "    \"\"\"\n",
    "    has_regions: bool = any([isinstance(i, (tuple, list)) and len(i) > 1 for i in labels.values()])\n",
    "    if has_regions:\n",
    "        assert regions_class_order is not None, f\"You have defined regions but regions_class_order is not set. \" \\\n",
    "                                                f\"You need that.\"\n",
    "    # channel names need strings as keys\n",
    "    keys = list(channel_names.keys())\n",
    "    for k in keys:\n",
    "        if not isinstance(k, str):\n",
    "            channel_names[str(k)] = channel_names[k]\n",
    "            del channel_names[k]\n",
    "\n",
    "    # labels need ints as values\n",
    "    for l in labels.keys():\n",
    "        value = labels[l]\n",
    "        if isinstance(value, (tuple, list)):\n",
    "            value = tuple([int(i) for i in value])\n",
    "            labels[l] = value\n",
    "        else:\n",
    "            labels[l] = int(labels[l])\n",
    "\n",
    "    dataset_json = {\n",
    "        'channel_names': channel_names,  # previously this was called 'modality'. I didn't like this so this is\n",
    "        # channel_names now. Live with it.\n",
    "        'labels': labels,\n",
    "        'numTraining': num_training_cases,\n",
    "        'file_ending': file_ending,\n",
    "    }\n",
    "\n",
    "    if dataset_name is not None:\n",
    "        dataset_json['name'] = dataset_name\n",
    "    if reference is not None:\n",
    "        dataset_json['reference'] = reference\n",
    "    if release is not None:\n",
    "        dataset_json['release'] = release\n",
    "    if license is not None:\n",
    "        dataset_json['licence'] = license\n",
    "    if description is not None:\n",
    "        dataset_json['description'] = description\n",
    "    if overwrite_image_reader_writer is not None:\n",
    "        dataset_json['overwrite_image_reader_writer'] = overwrite_image_reader_writer\n",
    "    if regions_class_order is not None:\n",
    "        dataset_json['regions_class_order'] = regions_class_order\n",
    "\n",
    "    dataset_json.update(kwargs)\n",
    "\n",
    "    save_json(dataset_json, join(output_folder, 'dataset.json'), sort_keys=False)\n",
    "    print('here')\n",
    "    \n",
    "generate_dataset_json(output_dir, channel_names, labels, num_training_cases, file_extension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scheme introduced above results in the following folder structure. Given is an example for the first Dataset of the MSD: BrainTumour. This dataset hat four input channels: FLAIR (0000), T1w (0001), T1gd (0002) and T2w (0003). Note that the imagesTs folder is optional and does not have to be present.\n",
    "\n",
    "```\n",
    "nnUNet_raw/Dataset001_BrainTumour/\n",
    "├── dataset.json\n",
    "├── imagesTr\n",
    "│   ├── BRATS_001_0000.nii.gz\n",
    "│   ├── BRATS_001_0001.nii.gz\n",
    "│   ├── BRATS_001_0002.nii.gz\n",
    "│   ├── BRATS_001_0003.nii.gz\n",
    "│   ├── BRATS_002_0000.nii.gz\n",
    "│   ├── BRATS_002_0001.nii.gz\n",
    "│   ├── BRATS_002_0002.nii.gz\n",
    "│   ├── BRATS_002_0003.nii.gz\n",
    "│   ├── ...\n",
    "├── imagesTs\n",
    "│   ├── BRATS_485_0000.nii.gz\n",
    "│   ├── BRATS_485_0001.nii.gz\n",
    "│   ├── BRATS_485_0002.nii.gz\n",
    "│   ├── BRATS_485_0003.nii.gz\n",
    "│   ├── BRATS_486_0000.nii.gz\n",
    "│   ├── BRATS_486_0001.nii.gz\n",
    "│   ├── BRATS_486_0002.nii.gz\n",
    "│   ├── BRATS_486_0003.nii.gz\n",
    "│   ├── ...\n",
    "└── labelsTr\n",
    "    ├── BRATS_001.nii.gz\n",
    "    ├── BRATS_002.nii.gz\n",
    "    ├── ...\n",
    "```\n",
    "\n",
    "Example of data arrangement\n",
    "\n",
    "```\n",
    "nnUNet_raw/Dataset002_Heart/\n",
    "├── dataset.json\n",
    "├── imagesTr\n",
    "│   ├── la_003_0000.nii.gz\n",
    "│   ├── la_004_0000.nii.gz\n",
    "│   ├── ...\n",
    "├── imagesTs\n",
    "│   ├── la_001_0000.nii.gz\n",
    "│   ├── la_002_0000.nii.gz\n",
    "│   ├── ...\n",
    "└── labelsTr\n",
    "    ├── la_003.nii.gz\n",
    "    ├── la_004.nii.gz\n",
    "    ├── ...\n",
    "```\n",
    "\n",
    "\n",
    "```json\n",
    "{ \n",
    " \"channel_names\": {  # formerly modalities\n",
    "   \"0\": \"T2\", \n",
    "   \"1\": \"ADC\"\n",
    " }, \n",
    " \"labels\": {  # THIS IS DIFFERENT NOW!\n",
    "   \"background\": 0,\n",
    "   \"PZ\": 1,\n",
    "   \"TZ\": 2\n",
    " }, \n",
    " \"numTraining\": 32, \n",
    " \"file_ending\": \".nii.gz\"\n",
    " \"overwrite_image_reader_writer\": \"SimpleITKIO\"  # optional! If not provided nnU-Net will automatically determine the ReaderWriter\n",
    " }\n",
    " ```\n",
    " The channel_names determine the normalization used by nnU-Net. If a channel is marked as 'CT', then a global normalization based on the intensities in the foreground pixels will be used. If it is something else, per-channel z-scoring will be used. Refer to the methods section in our paper for more details. nnU-Net v2 introduces a few more normalization schemes to choose from and allows you to define your own, see here for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Function to display CT and contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAT_ID = 3\n",
    "# DATA_DIRECTORY = \"/home/ivazquez/Repos/nnUNet/raw_data/neck_cta/anonymized\"\n",
    "WINDOW_WIDTH = 400 # HU\n",
    "WINDOW_CENTER = 40 # HU\n",
    "INITIAL_SLICE = None\n",
    "COLORMAP = 'gray'\n",
    "\n",
    "dt = DicomToolbox(patient_data_directory = DATA_DIRECTORY)\n",
    "dt.expected_data = ['ct', 'rtstruct']\n",
    "dt.uniform_slice_thickness = False\n",
    "dt.parse_dicom_files(PAT_ID, mask_resolution = 'ct', mask_names_only=False)\n",
    "\n",
    "ct = dt.ct.data # grab the ct data\n",
    "orig_coords = copy.deepcopy(dt.ct.coordinates) # grab the coordinates\n",
    "# ct, dt.ct.coordinates = resize_to_user_resolution(ct, dt.ct.coordinates, [1,1,1]) \n",
    "\n",
    "ct = apply_windowing(ct, WINDOW_WIDTH, WINDOW_CENTER) # apply windowing\n",
    "structures = [c for c in dt.contours]\n",
    "\n",
    "# Create a Select widget\n",
    "select_structures = Select(\n",
    "    options=structures,\n",
    "    value=structures[0],\n",
    "    description='Structures:',\n",
    "    rows=len(structures))\n",
    "\n",
    "display(HBox([select_structures]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, Listbox, Scrollbar\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import copy\n",
    "from dicom_tools import DicomToolbox  # Ensure this module is available\n",
    "\n",
    "class DicomViewer:\n",
    "    def __init__(self, root, data_directory, pat_id, window_width, window_center):\n",
    "        self.root = root\n",
    "        self.data_directory = data_directory\n",
    "        self.pat_id = pat_id\n",
    "        self.window_width = window_width\n",
    "        self.window_center = window_center\n",
    "\n",
    "        self.dt = DicomToolbox(patient_data_directory=data_directory)\n",
    "        self.dt.expected_data = ['ct', 'rtstruct']\n",
    "        self.dt.uniform_slice_thickness = False\n",
    "        self.dt.parse_dicom_files(pat_id, mask_resolution='ct', mask_names_only=False)\n",
    "\n",
    "        self.ct = self.dt.ct.data\n",
    "        self.orig_coords = copy.deepcopy(self.dt.ct.coordinates)\n",
    "        self.ct = self.apply_windowing(self.ct, window_width, window_center)\n",
    "        self.structures = [c for c in self.dt.contours]\n",
    "\n",
    "        self.create_widgets()\n",
    "        self.update_plot()\n",
    "\n",
    "    def create_widgets(self):\n",
    "        self.structure_listbox = Listbox(self.root, selectmode=tk.SINGLE)\n",
    "        for struct in self.structures:\n",
    "            self.structure_listbox.insert(tk.END, struct)\n",
    "        self.structure_listbox.bind('<<ListboxSelect>>', lambda event: self.update_plot())\n",
    "        self.structure_listbox.pack(side=tk.LEFT, fill=tk.Y)\n",
    "\n",
    "        scrollbar = Scrollbar(self.root)\n",
    "        scrollbar.pack(side=tk.LEFT, fill=tk.Y)\n",
    "        self.structure_listbox.config(yscrollcommand=scrollbar.set)\n",
    "        scrollbar.config(command=self.structure_listbox.yview)\n",
    "\n",
    "        self.figure, self.ax = plt.subplots(figsize=(7, 7))\n",
    "        self.canvas = FigureCanvasTkAgg(self.figure, master=self.root)\n",
    "        self.canvas.get_tk_widget().pack()\n",
    "\n",
    "        self.slice_var = tk.IntVar(value=self.ct.shape[0] // 2)\n",
    "        self.slice_slider = ttk.Scale(self.root, from_=0, to=self.ct.shape[0] - 1, orient=\"horizontal\", variable=self.slice_var)\n",
    "        self.slice_slider.pack(fill=tk.X)\n",
    "        self.slice_slider.bind(\"<Motion>\", lambda event: self.update_plot())\n",
    "\n",
    "        self.root.bind('<Left>', self.previous_slice)\n",
    "        self.root.bind('<Right>', self.next_slice)\n",
    "\n",
    "    def apply_windowing(self, image, window_width, window_center):\n",
    "        min_hu = window_center - window_width // 2\n",
    "        max_hu = window_center + window_width // 2\n",
    "        image = np.clip(image, min_hu, max_hu)\n",
    "        image = (image - min_hu) / (max_hu - min_hu) * 255.0\n",
    "        return image\n",
    "\n",
    "    def update_plot(self, event=None):\n",
    "        slice_idx = self.slice_var.get()\n",
    "        selected_idx = self.structure_listbox.curselection()\n",
    "        if selected_idx:\n",
    "            structure_name = self.structure_listbox.get(selected_idx)\n",
    "            structure = self.dt.contours[structure_name].data\n",
    "\n",
    "            self.ax.clear()\n",
    "            ct_extent = [self.dt.ct.coordinates.x.min(), self.dt.ct.coordinates.x.max(),\n",
    "                         self.dt.ct.coordinates.y.max(), self.dt.ct.coordinates.y.min()]\n",
    "            self.ax.imshow(self.ct[slice_idx], cmap='gray', interpolation='none', extent=ct_extent)\n",
    "            x, y = self.dt.ct.coordinates.x, self.dt.ct.coordinates.y\n",
    "            self.ax.contour(x, y, structure[slice_idx], levels=[0.5], colors='red')\n",
    "            self.ax.axis('off')\n",
    "\n",
    "            self.canvas.draw()\n",
    "\n",
    "    def previous_slice(self, event):\n",
    "        current_slice = self.slice_var.get()\n",
    "        if current_slice > 0:\n",
    "            self.slice_var.set(current_slice - 1)\n",
    "            self.update_plot()\n",
    "\n",
    "    def next_slice(self, event):\n",
    "        current_slice = self.slice_var.get()\n",
    "        if current_slice < self.ct.shape[0] - 1:\n",
    "            self.slice_var.set(current_slice + 1)\n",
    "            self.update_plot()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    root.title(\"DICOM Viewer\")\n",
    "\n",
    "    data_directory = \"/home/ivazquez/Documents/REPOS/nnUNet/raw_data/neck_cta/anonymized\"\n",
    "    pat_id = 1\n",
    "    window_width = 400\n",
    "    window_center = 40\n",
    "\n",
    "    viewer = DicomViewer(root, data_directory, pat_id, window_width, window_center)\n",
    "    root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
