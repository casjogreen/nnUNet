{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import numpy as np\n",
    "import json, os\n",
    "import seaborn as sns   \n",
    "import pandas as pd\n",
    "import copy\n",
    "from ipywidgets import interact, IntSlider, Select, HBox\n",
    "from utilities import apply_windowing, resize_to_user_resolution\n",
    "from dicom_tools import DicomToolbox   \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = \"/home/ivazquez/Documents/REPOS/nnUNet/raw_data/neck_cta/anonymized\"\n",
    "DATASET_NAME = 'neck_cta'\n",
    "RESAMPLING = {'apply': True, 'resolution': (1.0, 1.0, 1.0)}\n",
    "EXPECTED_DATA =['ct', 'rtstruct']\n",
    "LABELS = [\"common carotid lt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No user inputs were provided. Setting default values.\n"
     ]
    }
   ],
   "source": [
    "dt = DicomToolbox(patient_data_directory = DATA_DIRECTORY)\n",
    "dt.expected_data = EXPECTED_DATA\n",
    "dt.uniform_slice_thickness = False\n",
    "\n",
    "all_pat_ids = dt.identify_patient_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in all_patient_ids:\n",
    "#     dt.parse_dicom_files(p, mask_resolution='ct', mask_names_only=True)\n",
    "#     if contour not in dt.contours:\n",
    "#         print(f\"Patient {p} does not have {contour}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [pat for pat in all_pat_ids if pat not in ['2' and '21']]: \n",
    "    dt.parse_dicom_files(p, mask_resolution='ct', mask_names_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pat_id in tqdm(all_pat_ids, desc='Processing Patients'):\n",
    "    for label in TARGETS:\n",
    "        dt.dicom_files = dt.run_initial_check(pat_id)    \n",
    "        dt.ct = dt.parse_ct_study_files(dt.dicom_files['ct'])\n",
    "        all_contours = dt.parse_structure_files(files = sorted(dt.dicom_files['structures']), patient_id = pat_id, names_only = True)\n",
    "        if label not in all_contours:\n",
    "            print(f\"Patient {pat_id} does not have {label}\")\n",
    "            continue\n",
    "        contour = dt.parse_structure_files(files = sorted(self.dicom_files['structures']), patient_id = pat_id, mask_names = label, resolution = 'ct')\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_contours = [dt.parse_dicom_files(pat, mask_resolution='ct', mask_names_only=True) for pat in all_pat_ids]\n",
    "\n",
    "# Assuming all_contours is a list of contour names\n",
    "unique_contours, counts = np.unique(all_contours, return_counts=True)\n",
    "\n",
    "# Printing unique contours and their counts\n",
    "for contour, count in zip(unique_contours, counts):\n",
    "    print(f\"{contour}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "# Your NumPy array (replace with your actual data)\n",
    "array_data = np.random.rand(64, 64, 32)  # Example: 64x64x32 array\n",
    "\n",
    "# Define voxel spacing: [x, y, z]\n",
    "voxel_spacing = [2.0, 2.0, 2.5]\n",
    "\n",
    "# Create an affine matrix with voxel spacing\n",
    "affine = np.eye(4)\n",
    "affine[0, 0] = voxel_spacing[0]  # Spacing in x\n",
    "affine[1, 1] = voxel_spacing[1]  # Spacing in y\n",
    "affine[2, 2] = voxel_spacing[2]  # Spacing in z\n",
    "\n",
    "# Create a NIfTI1Image object with specified voxel spacing\n",
    "nifti_image = nib.Nifti1Image(array_data, affine=affine)\n",
    "\n",
    "# Save the image to a NIfTI file\n",
    "nib.save(nifti_image, 'my_nifti_file_with_spacing.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "from batchgenerators.utilities.file_and_folder_operations import save_json, join\n",
    "\n",
    "\n",
    "def generate_dataset_json(output_folder: str,\n",
    "                          channel_names: dict,\n",
    "                          labels: dict,\n",
    "                          num_training_cases: int,\n",
    "                          file_ending: str,\n",
    "                          regions_class_order: Tuple[int, ...] = None,\n",
    "                          dataset_name: str = None, reference: str = None, release: str = None, license: str = None,\n",
    "                          description: str = None,\n",
    "                          overwrite_image_reader_writer: str = None, **kwargs):\n",
    "    \"\"\"\n",
    "    Generates a dataset.json file in the output folder\n",
    "\n",
    "    channel_names:\n",
    "        Channel names must map the index to the name of the channel, example:\n",
    "        {\n",
    "            0: 'T1',\n",
    "            1: 'CT'\n",
    "        }\n",
    "        Note that the channel names may influence the normalization scheme!! Learn more in the documentation.\n",
    "\n",
    "    labels:\n",
    "        This will tell nnU-Net what labels to expect. Important: This will also determine whether you use region-based training or not.\n",
    "        Example regular labels:\n",
    "        {\n",
    "            'background': 0,\n",
    "            'left atrium': 1,\n",
    "            'some other label': 2\n",
    "        }\n",
    "        Example region-based training:\n",
    "        {\n",
    "            'background': 0,\n",
    "            'whole tumor': (1, 2, 3),\n",
    "            'tumor core': (2, 3),\n",
    "            'enhancing tumor': 3\n",
    "        }\n",
    "\n",
    "        Remember that nnU-Net expects consecutive values for labels! nnU-Net also expects 0 to be background!\n",
    "\n",
    "    num_training_cases: is used to double check all cases are there!\n",
    "\n",
    "    file_ending: needed for finding the files correctly. IMPORTANT! File endings must match between images and\n",
    "    segmentations!\n",
    "\n",
    "    dataset_name, reference, release, license, description: self-explanatory and not used by nnU-Net. Just for\n",
    "    completeness and as a reminder that these would be great!\n",
    "\n",
    "    overwrite_image_reader_writer: If you need a special IO class for your dataset you can derive it from\n",
    "    BaseReaderWriter, place it into nnunet.imageio and reference it here by name\n",
    "\n",
    "    kwargs: whatever you put here will be placed in the dataset.json as well\n",
    "\n",
    "    \"\"\"\n",
    "    has_regions: bool = any([isinstance(i, (tuple, list)) and len(i) > 1 for i in labels.values()])\n",
    "    if has_regions:\n",
    "        assert regions_class_order is not None, f\"You have defined regions but regions_class_order is not set. \" \\\n",
    "                                                f\"You need that.\"\n",
    "    # channel names need strings as keys\n",
    "    keys = list(channel_names.keys())\n",
    "    for k in keys:\n",
    "        if not isinstance(k, str):\n",
    "            channel_names[str(k)] = channel_names[k]\n",
    "            del channel_names[k]\n",
    "\n",
    "    # labels need ints as values\n",
    "    for l in labels.keys():\n",
    "        value = labels[l]\n",
    "        if isinstance(value, (tuple, list)):\n",
    "            value = tuple([int(i) for i in value])\n",
    "            labels[l] = value\n",
    "        else:\n",
    "            labels[l] = int(labels[l])\n",
    "\n",
    "    dataset_json = {\n",
    "        'channel_names': channel_names,  # previously this was called 'modality'. I didn't like this so this is\n",
    "        # channel_names now. Live with it.\n",
    "        'labels': labels,\n",
    "        'numTraining': num_training_cases,\n",
    "        'file_ending': file_ending,\n",
    "    }\n",
    "\n",
    "    if dataset_name is not None:\n",
    "        dataset_json['name'] = dataset_name\n",
    "    if reference is not None:\n",
    "        dataset_json['reference'] = reference\n",
    "    if release is not None:\n",
    "        dataset_json['release'] = release\n",
    "    if license is not None:\n",
    "        dataset_json['licence'] = license\n",
    "    if description is not None:\n",
    "        dataset_json['description'] = description\n",
    "    if overwrite_image_reader_writer is not None:\n",
    "        dataset_json['overwrite_image_reader_writer'] = overwrite_image_reader_writer\n",
    "    if regions_class_order is not None:\n",
    "        dataset_json['regions_class_order'] = regions_class_order\n",
    "\n",
    "    dataset_json.update(kwargs)\n",
    "\n",
    "    save_json(dataset_json, join(output_folder, 'dataset.json'), sort_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scheme introduced above results in the following folder structure. Given is an example for the first Dataset of the MSD: BrainTumour. This dataset hat four input channels: FLAIR (0000), T1w (0001), T1gd (0002) and T2w (0003). Note that the imagesTs folder is optional and does not have to be present.\n",
    "\n",
    "```\n",
    "nnUNet_raw/Dataset001_BrainTumour/\n",
    "├── dataset.json\n",
    "├── imagesTr\n",
    "│   ├── BRATS_001_0000.nii.gz\n",
    "│   ├── BRATS_001_0001.nii.gz\n",
    "│   ├── BRATS_001_0002.nii.gz\n",
    "│   ├── BRATS_001_0003.nii.gz\n",
    "│   ├── BRATS_002_0000.nii.gz\n",
    "│   ├── BRATS_002_0001.nii.gz\n",
    "│   ├── BRATS_002_0002.nii.gz\n",
    "│   ├── BRATS_002_0003.nii.gz\n",
    "│   ├── ...\n",
    "├── imagesTs\n",
    "│   ├── BRATS_485_0000.nii.gz\n",
    "│   ├── BRATS_485_0001.nii.gz\n",
    "│   ├── BRATS_485_0002.nii.gz\n",
    "│   ├── BRATS_485_0003.nii.gz\n",
    "│   ├── BRATS_486_0000.nii.gz\n",
    "│   ├── BRATS_486_0001.nii.gz\n",
    "│   ├── BRATS_486_0002.nii.gz\n",
    "│   ├── BRATS_486_0003.nii.gz\n",
    "│   ├── ...\n",
    "└── labelsTr\n",
    "    ├── BRATS_001.nii.gz\n",
    "    ├── BRATS_002.nii.gz\n",
    "    ├── ...\n",
    "```\n",
    "\n",
    "Example of data arrangement\n",
    "\n",
    "```\n",
    "nnUNet_raw/Dataset002_Heart/\n",
    "├── dataset.json\n",
    "├── imagesTr\n",
    "│   ├── la_003_0000.nii.gz\n",
    "│   ├── la_004_0000.nii.gz\n",
    "│   ├── ...\n",
    "├── imagesTs\n",
    "│   ├── la_001_0000.nii.gz\n",
    "│   ├── la_002_0000.nii.gz\n",
    "│   ├── ...\n",
    "└── labelsTr\n",
    "    ├── la_003.nii.gz\n",
    "    ├── la_004.nii.gz\n",
    "    ├── ...\n",
    "```\n",
    "\n",
    "\n",
    "```json\n",
    "{ \n",
    " \"channel_names\": {  # formerly modalities\n",
    "   \"0\": \"T2\", \n",
    "   \"1\": \"ADC\"\n",
    " }, \n",
    " \"labels\": {  # THIS IS DIFFERENT NOW!\n",
    "   \"background\": 0,\n",
    "   \"PZ\": 1,\n",
    "   \"TZ\": 2\n",
    " }, \n",
    " \"numTraining\": 32, \n",
    " \"file_ending\": \".nii.gz\"\n",
    " \"overwrite_image_reader_writer\": \"SimpleITKIO\"  # optional! If not provided nnU-Net will automatically determine the ReaderWriter\n",
    " }\n",
    " ```\n",
    " The channel_names determine the normalization used by nnU-Net. If a channel is marked as 'CT', then a global normalization based on the intensities in the foreground pixels will be used. If it is something else, per-channel z-scoring will be used. Refer to the methods section in our paper for more details. nnU-Net v2 introduces a few more normalization schemes to choose from and allows you to define your own, see here for more information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
