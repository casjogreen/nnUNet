{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import json, os, logging, random, copy, shutil\n",
    "import seaborn as sns, pandas as pd, numpy as np, nibabel as nib\n",
    "from ipywidgets import interact, IntSlider, Select, HBox\n",
    "from utilities import apply_windowing, resize_to_user_resolution\n",
    "from dicom_tools import DicomToolbox   \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = \"/home/ivazquez/Documents/REPOS/nnUNet/raw_data\" #\"/home/ivazquez/Repos/nnUNet/raw_data/neck_cta/anonymized\"\n",
    "# OUTPUT_DIRECTORY = \"/home/ivazquez/Repos/nnUNet/raw_data/neck_cta/nnUNet_raw_data_base\"\n",
    "EXPECTED_DATA =['ct', 'rtstruct']\n",
    "LABELS = [\"common carotid lt\"]\n",
    "DATASET_NAME = 'neck_cta'\n",
    "MODALITY = 'CT'\n",
    "TEST_SET_SIZE = 2\n",
    "LEAVE_OUT = [2,3,4, 14,21, 7]\n",
    "\n",
    "\n",
    "params = {\n",
    "    'DATA_DIRECTORY': DATA_DIRECTORY,\n",
    "    'RESAMPLING': {'apply': True, 'resolution': (1.0, 1.0, 1.0)},\n",
    "    'LABELS': [\"common carotid lt\"],\n",
    "    'DATASET_NAME': /,\n",
    "    'MODALITY': MODALITY,\n",
    "    'TEST_SET_SIZE': TEST_SET_SIZE,\n",
    "    'LEAVE_OUT': LEAVE_OUT\n",
    "    'INPUT_MODALITIES': ['ct'],\n",
    "    'OUTPUT_MODALITIES': ['rtstruct']\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No user inputs were provided. Setting default values.\n"
     ]
    }
   ],
   "source": [
    "dt = DicomToolbox(patient_data_directory = DATA_DIRECTORY)\n",
    "dt.expected_data = EXPECTED_DATA\n",
    "dt.uniform_slice_thickness = False\n",
    "\n",
    "all_pat_ids = dt.identify_patient_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in all_pat_ids:\n",
    "    dt.parse_dicom_files(p, mask_resolution='ct', mask_names_only=True)\n",
    "    if LABELS[0] not in dt.contours:\n",
    "        print(f\"Patient {p} does not have {LABELS[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [pat for pat in all_pat_ids if pat not in ['2' and '21']]: \n",
    "    dt.parse_dicom_files(p, mask_resolution='ct', mask_names_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No user inputs were provided. Setting default values.\n"
     ]
    }
   ],
   "source": [
    "import json, tqdm\n",
    "\n",
    "class Preprocessing(DicomToolbox):\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        super().__init__(patient_data_directory=params['DATA_DIRECTORY'])\n",
    "        self.expected_data = params['INPUT_MODALITIES'] + params['OUTPUT_MODALITIES']\n",
    "        \n",
    "    def get_data_insight(self):\n",
    "        all_pat_ids = self.identify_patient_files()\n",
    "        data_insight = {p:{} for p in all_pat_ids}\n",
    "        \n",
    "        for p in tqdm(all_pat_ids, desc=\"Getting data insight\"):\n",
    "            self.parse_dicom_files(p, mask_resolution='ct', mask_names_only=True)\n",
    "            # TODO: function in dicom tools to get available modalities\n",
    "            data_insight[p]['ct']={'shape': self.ct.data.shape, \n",
    "                                   'min': self.ct.data.min(),\n",
    "                                   'max': self.ct.data.max(),\n",
    "                                   'dx': self.ct.coordinates.dx,\n",
    "                                   'dy': self.ct.coordinates.dy,\n",
    "                                   'dz': self.ct.coordinates.dz}\n",
    "            data_insight[p]['rtstruct'] = {k: v for k, v in self.contours}\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            if LABELS[0] not in self.contours:\n",
    "                print(f\"Patient {p} does not have {LABELS[0]}\")\n",
    "        \n",
    "        for p in [pat for pat in all_pat_ids if pat not in LEAVE_OUT]: \n",
    "            self.parse_dicom_files(p, mask_resolution='ct', mask_names_only=True)\n",
    "            \n",
    "    def save_as_nifti(self):\n",
    "       pass        \n",
    "    # def load_data(self):\n",
    "        \n",
    "        # self.expected_data = EXPECTED_DATA\n",
    "        # self.uniform_slice_thickness = False\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05117e1319e640bb99cedb162d3dea1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time \n",
    "from rich.progress import track\n",
    "\n",
    "for n in track(range(20), description=\"Processing...\"):\n",
    "    time.sleep(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_pat_ids = [int(pat) for pat in all_pat_ids if int(pat) not in LEAVE_OUT]\n",
    "\n",
    "# Randomly select test set\n",
    "test_set = random.sample(all_pat_ids, TEST_SET_SIZE)\n",
    "train_set = [pat for pat in all_pat_ids if pat not in test_set]\n",
    "\n",
    "# Prepare output directories\n",
    "output_dir = os.path.join(os.path.dirname(DATA_DIRECTORY), 'preprocessed')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"Created output directory: {output_dir}\")\n",
    "    \n",
    "for dir_name in ['imagesTr', 'imagesTs', 'labelsTr', 'labelsTs']:\n",
    "    if os.path.exists(os.path.join(output_dir, dir_name)): shutil.rmtree(os.path.join(output_dir, dir_name))\n",
    "    os.makedirs(os.path.join(output_dir, dir_name), exist_ok=True)\n",
    "\n",
    "def save_as_nifti(array_data, voxel_spacing, file_name):\n",
    "\n",
    "    if not isinstance(voxel_spacing, (list, tuple)) or len(voxel_spacing) != 3:\n",
    "        raise ValueError(\"voxel_spacing must be a list or tuple with 3 elements.\")\n",
    "\n",
    "    affine = np.eye(4)\n",
    "    affine[0, 0] = voxel_spacing[0]  # Spacing in x\n",
    "    affine[1, 1] = voxel_spacing[1]  # Spacing in y\n",
    "    affine[2, 2] = voxel_spacing[2]  # Spacing in z\n",
    "\n",
    "    # Create a NIfTI1Image object with specified voxel spacing\n",
    "    nifti_image = nib.Nifti1Image(array_data, affine=affine)\n",
    "\n",
    "    # Save the image to a NIfTI file\n",
    "    nib.save(nifti_image, f\"{file_name}.nii.gz\")\n",
    " \n",
    "def process_patients(all_pat_ids, dt, LABELS, RESAMPLING, output_dir, dataset):\n",
    "    \n",
    "    for index, pat_id in enumerate(tqdm(all_pat_ids, desc=f'Processing {dataset} patients')):\n",
    "        \n",
    "        dt.dicom_files = dt.run_initial_check(pat_id)  # Grab the dicom files\n",
    "        dt.ct = dt.parse_ct_study_files(dt.dicom_files['ct'])  # Parse the CT files\n",
    "        all_contours = dt.parse_structure_files(files=sorted(dt.dicom_files['structures']), patient_id=pat_id, names_only=True)  # Parse the structure files\n",
    "        orig_coords = copy.deepcopy(dt.ct.coordinates)  # store copy of original CT coordinates\n",
    "\n",
    "        # Resize CT if necessary\n",
    "        ct, coords = resize_to_user_resolution(dt.ct.data, orig_coords, RESAMPLING['resolution'], fill_value=dt.ct.data.min()) if RESAMPLING['apply'] else (dt.ct.data, dt.ct.coordinates)\n",
    "        \n",
    "        # Save the CT\n",
    "        if dataset == 'train':\n",
    "            save_as_nifti(ct, RESAMPLING['resolution'], os.path.join(output_dir, 'imagesTr', f\"{dataset}Patient_{index:03}_0000\"))\n",
    "        else:\n",
    "            save_as_nifti(ct, RESAMPLING['resolution'], os.path.join(output_dir, 'imagesTs', f\"{dataset}Patient_{index:03}_0000\"))\n",
    "        \n",
    "        # Prepare the labels\n",
    "        labels_dict = {}\n",
    "\n",
    "        for label in LABELS:\n",
    "            if label not in all_contours: break\n",
    "            contour = dt.parse_structure_files(files=sorted(dt.dicom_files['structures']), patient_id=pat_id, mask_names=label, resolution='ct')\n",
    "\n",
    "            # Resize the mask if necessary\n",
    "            mask, _ = resize_to_user_resolution(contour[label].data, orig_coords, RESAMPLING['resolution'], fill_value=0) if RESAMPLING['apply'] else (contour[label].data, None)\n",
    "\n",
    "            labels_dict[label] = mask\n",
    "\n",
    "        # Save the labels\n",
    "        for l in labels_dict:\n",
    "            if dataset == 'train':\n",
    "                save_as_nifti(labels_dict[l], RESAMPLING['resolution'], os.path.join(output_dir, 'labelsTr', f\"{}Patient_{index:03}\"))\n",
    "            else:\n",
    "                save_as_nifti(labels_dict[l], RESAMPLING['resolution'], os.path.join(output_dir, 'labelsTs', f\"patient_{index:03}\"))\n",
    "        \n",
    "       \n",
    "process_patients(test_set, dt, LABELS, RESAMPLING, output_dir, 'test')\n",
    "process_patients(train_set, dt, LABELS, RESAMPLING, output_dir, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_contours = [dt.parse_dicom_files(pat, mask_resolution='ct', mask_names_only=True) for pat in all_pat_ids]\n",
    "\n",
    "# Assuming all_contours is a list of contour names\n",
    "unique_contours, counts = np.unique(all_contours, return_counts=True)\n",
    "\n",
    "# Printing unique contours and their counts\n",
    "for contour, count in zip(unique_contours, counts):\n",
    "    print(f\"{contour}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "# Your NumPy array (replace with your actual data)\n",
    "array_data = np.random.rand(64, 64, 32)  # Example: 64x64x32 array\n",
    "\n",
    "# Define voxel spacing: [x, y, z]\n",
    "voxel_spacing = [2.0, 2.0, 2.5]\n",
    "\n",
    "# Create an affine matrix with voxel spacing\n",
    "affine = np.eye(4)\n",
    "affine[0, 0] = voxel_spacing[0]  # Spacing in x\n",
    "affine[1, 1] = voxel_spacing[1]  # Spacing in y\n",
    "affine[2, 2] = voxel_spacing[2]  # Spacing in z\n",
    "\n",
    "# Create a NIfTI1Image object with specified voxel spacing\n",
    "nifti_image = nib.Nifti1Image(array_data, affine=affine)\n",
    "\n",
    "# Save the image to a NIfTI file\n",
    "nib.save(nifti_image, 'my_nifti_file_with_spacing.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "from batchgenerators.utilities.file_and_folder_operations import save_json, join\n",
    "\n",
    "channel_names = {0: 'CT'}\n",
    "labels = {'common carotid lt': 1,\n",
    "          'background': 0}\n",
    "num_training_cases = len(os.listdir(os.path.join(output_dir, 'imagesTr')))\n",
    "file_extension = '.nii.gz'\n",
    "\n",
    "def generate_dataset_json(output_folder: str,\n",
    "                          channel_names: dict,\n",
    "                          labels: dict,\n",
    "                          num_training_cases: int,\n",
    "                          file_ending: str,\n",
    "                          regions_class_order: Tuple[int, ...] = None,\n",
    "                          dataset_name: str = None, reference: str = None, release: str = None, license: str = None,\n",
    "                          description: str = None,\n",
    "                          overwrite_image_reader_writer: str = None, **kwargs):\n",
    "    \"\"\"\n",
    "    Generates a dataset.json file in the output folder\n",
    "\n",
    "    channel_names:\n",
    "        Channel names must map the index to the name of the channel, example:\n",
    "        {\n",
    "            0: 'T1',\n",
    "            1: 'CT'\n",
    "        }\n",
    "        Note that the channel names may influence the normalization scheme!! Learn more in the documentation.\n",
    "\n",
    "    labels:\n",
    "        This will tell nnU-Net what labels to expect. Important: This will also determine whether you use region-based training or not.\n",
    "        Example regular labels:\n",
    "        {\n",
    "            'background': 0,\n",
    "            'left atrium': 1,\n",
    "            'some other label': 2\n",
    "        }\n",
    "        Example region-based training:\n",
    "        {\n",
    "            'background': 0,\n",
    "            'whole tumor': (1, 2, 3),\n",
    "            'tumor core': (2, 3),\n",
    "            'enhancing tumor': 3\n",
    "        }\n",
    "\n",
    "        Remember that nnU-Net expects consecutive values for labels! nnU-Net also expects 0 to be background!\n",
    "\n",
    "    num_training_cases: is used to double check all cases are there!\n",
    "\n",
    "    file_ending: needed for finding the files correctly. IMPORTANT! File endings must match between images and\n",
    "    segmentations!\n",
    "\n",
    "    dataset_name, reference, release, license, description: self-explanatory and not used by nnU-Net. Just for\n",
    "    completeness and as a reminder that these would be great!\n",
    "\n",
    "    overwrite_image_reader_writer: If you need a special IO class for your dataset you can derive it from\n",
    "    BaseReaderWriter, place it into nnunet.imageio and reference it here by name\n",
    "\n",
    "    kwargs: whatever you put here will be placed in the dataset.json as well\n",
    "\n",
    "    \"\"\"\n",
    "    has_regions: bool = any([isinstance(i, (tuple, list)) and len(i) > 1 for i in labels.values()])\n",
    "    if has_regions:\n",
    "        assert regions_class_order is not None, f\"You have defined regions but regions_class_order is not set. \" \\\n",
    "                                                f\"You need that.\"\n",
    "    # channel names need strings as keys\n",
    "    keys = list(channel_names.keys())\n",
    "    for k in keys:\n",
    "        if not isinstance(k, str):\n",
    "            channel_names[str(k)] = channel_names[k]\n",
    "            del channel_names[k]\n",
    "\n",
    "    # labels need ints as values\n",
    "    for l in labels.keys():\n",
    "        value = labels[l]\n",
    "        if isinstance(value, (tuple, list)):\n",
    "            value = tuple([int(i) for i in value])\n",
    "            labels[l] = value\n",
    "        else:\n",
    "            labels[l] = int(labels[l])\n",
    "\n",
    "    dataset_json = {\n",
    "        'channel_names': channel_names,  # previously this was called 'modality'. I didn't like this so this is\n",
    "        # channel_names now. Live with it.\n",
    "        'labels': labels,\n",
    "        'numTraining': num_training_cases,\n",
    "        'file_ending': file_ending,\n",
    "    }\n",
    "\n",
    "    if dataset_name is not None:\n",
    "        dataset_json['name'] = dataset_name\n",
    "    if reference is not None:\n",
    "        dataset_json['reference'] = reference\n",
    "    if release is not None:\n",
    "        dataset_json['release'] = release\n",
    "    if license is not None:\n",
    "        dataset_json['licence'] = license\n",
    "    if description is not None:\n",
    "        dataset_json['description'] = description\n",
    "    if overwrite_image_reader_writer is not None:\n",
    "        dataset_json['overwrite_image_reader_writer'] = overwrite_image_reader_writer\n",
    "    if regions_class_order is not None:\n",
    "        dataset_json['regions_class_order'] = regions_class_order\n",
    "\n",
    "    dataset_json.update(kwargs)\n",
    "\n",
    "    save_json(dataset_json, join(output_folder, 'dataset.json'), sort_keys=False)\n",
    "    \n",
    "generate_dataset_json(output_dir, channel_names, labels, num_training_cases, file_extension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scheme introduced above results in the following folder structure. Given is an example for the first Dataset of the MSD: BrainTumour. This dataset hat four input channels: FLAIR (0000), T1w (0001), T1gd (0002) and T2w (0003). Note that the imagesTs folder is optional and does not have to be present.\n",
    "\n",
    "```\n",
    "nnUNet_raw/Dataset001_BrainTumour/\n",
    "├── dataset.json\n",
    "├── imagesTr\n",
    "│   ├── BRATS_001_0000.nii.gz\n",
    "│   ├── BRATS_001_0001.nii.gz\n",
    "│   ├── BRATS_001_0002.nii.gz\n",
    "│   ├── BRATS_001_0003.nii.gz\n",
    "│   ├── BRATS_002_0000.nii.gz\n",
    "│   ├── BRATS_002_0001.nii.gz\n",
    "│   ├── BRATS_002_0002.nii.gz\n",
    "│   ├── BRATS_002_0003.nii.gz\n",
    "│   ├── ...\n",
    "├── imagesTs\n",
    "│   ├── BRATS_485_0000.nii.gz\n",
    "│   ├── BRATS_485_0001.nii.gz\n",
    "│   ├── BRATS_485_0002.nii.gz\n",
    "│   ├── BRATS_485_0003.nii.gz\n",
    "│   ├── BRATS_486_0000.nii.gz\n",
    "│   ├── BRATS_486_0001.nii.gz\n",
    "│   ├── BRATS_486_0002.nii.gz\n",
    "│   ├── BRATS_486_0003.nii.gz\n",
    "│   ├── ...\n",
    "└── labelsTr\n",
    "    ├── BRATS_001.nii.gz\n",
    "    ├── BRATS_002.nii.gz\n",
    "    ├── ...\n",
    "```\n",
    "\n",
    "Example of data arrangement\n",
    "\n",
    "```\n",
    "nnUNet_raw/Dataset002_Heart/\n",
    "├── dataset.json\n",
    "├── imagesTr\n",
    "│   ├── la_003_0000.nii.gz\n",
    "│   ├── la_004_0000.nii.gz\n",
    "│   ├── ...\n",
    "├── imagesTs\n",
    "│   ├── la_001_0000.nii.gz\n",
    "│   ├── la_002_0000.nii.gz\n",
    "│   ├── ...\n",
    "└── labelsTr\n",
    "    ├── la_003.nii.gz\n",
    "    ├── la_004.nii.gz\n",
    "    ├── ...\n",
    "```\n",
    "\n",
    "\n",
    "```json\n",
    "{ \n",
    " \"channel_names\": {  # formerly modalities\n",
    "   \"0\": \"T2\", \n",
    "   \"1\": \"ADC\"\n",
    " }, \n",
    " \"labels\": {  # THIS IS DIFFERENT NOW!\n",
    "   \"background\": 0,\n",
    "   \"PZ\": 1,\n",
    "   \"TZ\": 2\n",
    " }, \n",
    " \"numTraining\": 32, \n",
    " \"file_ending\": \".nii.gz\"\n",
    " \"overwrite_image_reader_writer\": \"SimpleITKIO\"  # optional! If not provided nnU-Net will automatically determine the ReaderWriter\n",
    " }\n",
    " ```\n",
    " The channel_names determine the normalization used by nnU-Net. If a channel is marked as 'CT', then a global normalization based on the intensities in the foreground pixels will be used. If it is something else, per-channel z-scoring will be used. Refer to the methods section in our paper for more details. nnU-Net v2 introduces a few more normalization schemes to choose from and allows you to define your own, see here for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Function to display CT and contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAT_ID = 14\n",
    "DATA_DIRECTORY = \"/home/ivazquez/Repos/nnUNet/raw_data/neck_cta/anonymized\"\n",
    "WINDOW_WIDTH = 400 # HU\n",
    "WINDOW_CENTER = 40 # HU\n",
    "INITIAL_SLICE = None\n",
    "COLORMAP = 'gray'\n",
    "\n",
    "dt = DicomToolbox(patient_data_directory = DATA_DIRECTORY)\n",
    "dt.expected_data = ['ct', 'rtstruct']\n",
    "dt.uniform_slice_thickness = False\n",
    "dt.parse_dicom_files(PAT_ID, mask_resolution = 'ct', mask_names_only=False)\n",
    "\n",
    "ct = dt.ct.data # grab the ct data\n",
    "orig_coords = copy.deepcopy(dt.ct.coordinates) # grab the coordinates\n",
    "# ct, dt.ct.coordinates = resize_to_user_resolution(ct, dt.ct.coordinates, [1,1,1]) \n",
    "\n",
    "ct = apply_windowing(ct, WINDOW_WIDTH, WINDOW_CENTER) # apply windowing\n",
    "structures = [c for c in dt.contours]\n",
    "\n",
    "# Create a Select widget\n",
    "select_structures = Select(\n",
    "    options=structures,\n",
    "    value=structures[0],\n",
    "    description='Structures:',\n",
    "    rows=len(structures))\n",
    "\n",
    "display(HBox([select_structures]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, Listbox, Scrollbar\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import copy\n",
    "from dicom_tools import DicomToolbox  # Ensure this module is available\n",
    "\n",
    "class DicomViewer:\n",
    "    def __init__(self, root, data_directory, pat_id, window_width, window_center):\n",
    "        self.root = root\n",
    "        self.data_directory = data_directory\n",
    "        self.pat_id = pat_id\n",
    "        self.window_width = window_width\n",
    "        self.window_center = window_center\n",
    "\n",
    "        self.dt = DicomToolbox(patient_data_directory=data_directory)\n",
    "        self.dt.expected_data = ['ct', 'rtstruct']\n",
    "        self.dt.uniform_slice_thickness = False\n",
    "        self.dt.parse_dicom_files(pat_id, mask_resolution='ct', mask_names_only=False)\n",
    "\n",
    "        self.ct = self.dt.ct.data\n",
    "        self.orig_coords = copy.deepcopy(self.dt.ct.coordinates)\n",
    "        self.ct = self.apply_windowing(self.ct, window_width, window_center)\n",
    "        self.structures = [c for c in self.dt.contours]\n",
    "\n",
    "        self.create_widgets()\n",
    "        self.update_plot()\n",
    "\n",
    "    def create_widgets(self):\n",
    "        self.structure_listbox = Listbox(self.root, selectmode=tk.SINGLE)\n",
    "        for struct in self.structures:\n",
    "            self.structure_listbox.insert(tk.END, struct)\n",
    "        self.structure_listbox.bind('<<ListboxSelect>>', lambda event: self.update_plot())\n",
    "        self.structure_listbox.pack(side=tk.LEFT, fill=tk.Y)\n",
    "\n",
    "        scrollbar = Scrollbar(self.root)\n",
    "        scrollbar.pack(side=tk.LEFT, fill=tk.Y)\n",
    "        self.structure_listbox.config(yscrollcommand=scrollbar.set)\n",
    "        scrollbar.config(command=self.structure_listbox.yview)\n",
    "\n",
    "        self.figure, self.ax = plt.subplots(figsize=(7, 7))\n",
    "        self.canvas = FigureCanvasTkAgg(self.figure, master=self.root)\n",
    "        self.canvas.get_tk_widget().pack()\n",
    "\n",
    "        self.slice_var = tk.IntVar(value=self.ct.shape[0] // 2)\n",
    "        self.slice_slider = ttk.Scale(self.root, from_=0, to=self.ct.shape[0] - 1, orient=\"horizontal\", variable=self.slice_var)\n",
    "        self.slice_slider.pack(fill=tk.X)\n",
    "        self.slice_slider.bind(\"<Motion>\", lambda event: self.update_plot())\n",
    "\n",
    "        self.root.bind('<Left>', self.previous_slice)\n",
    "        self.root.bind('<Right>', self.next_slice)\n",
    "\n",
    "    def apply_windowing(self, image, window_width, window_center):\n",
    "        min_hu = window_center - window_width // 2\n",
    "        max_hu = window_center + window_width // 2\n",
    "        image = np.clip(image, min_hu, max_hu)\n",
    "        image = (image - min_hu) / (max_hu - min_hu) * 255.0\n",
    "        return image\n",
    "\n",
    "    def update_plot(self, event=None):\n",
    "        slice_idx = self.slice_var.get()\n",
    "        selected_idx = self.structure_listbox.curselection()\n",
    "        if selected_idx:\n",
    "            structure_name = self.structure_listbox.get(selected_idx)\n",
    "            structure = self.dt.contours[structure_name].data\n",
    "\n",
    "            self.ax.clear()\n",
    "            ct_extent = [self.dt.ct.coordinates.x.min(), self.dt.ct.coordinates.x.max(),\n",
    "                         self.dt.ct.coordinates.y.max(), self.dt.ct.coordinates.y.min()]\n",
    "            self.ax.imshow(self.ct[slice_idx], cmap='gray', interpolation='none', extent=ct_extent)\n",
    "            x, y = self.dt.ct.coordinates.x, self.dt.ct.coordinates.y\n",
    "            self.ax.contour(x, y, structure[slice_idx], levels=[0.5], colors='red')\n",
    "            self.ax.axis('off')\n",
    "\n",
    "            self.canvas.draw()\n",
    "\n",
    "    def previous_slice(self, event):\n",
    "        current_slice = self.slice_var.get()\n",
    "        if current_slice > 0:\n",
    "            self.slice_var.set(current_slice - 1)\n",
    "            self.update_plot()\n",
    "\n",
    "    def next_slice(self, event):\n",
    "        current_slice = self.slice_var.get()\n",
    "        if current_slice < self.ct.shape[0] - 1:\n",
    "            self.slice_var.set(current_slice + 1)\n",
    "            self.update_plot()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    root.title(\"DICOM Viewer\")\n",
    "\n",
    "    data_directory = \"/home/ivazquez/Documents/REPOS/nnUNet/raw_data/neck_cta/anonymized\"\n",
    "    pat_id = 1\n",
    "    window_width = 400\n",
    "    window_center = 40\n",
    "\n",
    "    viewer = DicomViewer(root, data_directory, pat_id, window_width, window_center)\n",
    "    root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
