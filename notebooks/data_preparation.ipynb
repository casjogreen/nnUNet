{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import json, os, logging, random, copy, shutil\n",
    "import seaborn as sns, pandas as pd, numpy as np, nibabel as nib\n",
    "from ipywidgets import interact, IntSlider, Select, HBox\n",
    "from utilities import apply_windowing, resize_to_user_resolution\n",
    "from dicom_tools import DicomToolbox   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get environment variables\n",
    "import os\n",
    "\n",
    "# Replace 'YOUR_ENV_VAR' with the name of your environment variable\n",
    "env_var_value = os.getenv('nnUNet_raw')\n",
    "\n",
    "print(env_var_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf58a4a998f8467683addb8a5f83e1d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33ef0f6128f40b88e975bdeb5472399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving training data:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778d18e590b741859dd8a349cf444bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving test data:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from dicom_tools import DicomTools   \n",
    "import logging, os, json, random, copy, shutil, h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np, nibabel as nib\n",
    "from utilities import apply_windowing, resize_to_user_resolution\n",
    "from typing import Tuple\n",
    "\n",
    "from batchgenerators.utilities.file_and_folder_operations import save_json, join\n",
    "\n",
    "params = {\n",
    "    'DATA_DIRECTORY':  \"/home/ivazquez/Data/anonymized/neck_cta\", #, \"/home/ivazquez/Documents/Data/liver\",\n",
    "    'PREPROCESSED_DATA_DIRECTORY': \"/home/ivazquez/Repos/nnUNet/preprocessed_data/preprocessed_hdf5_files/preprocessed_Dataset001_NeckCTA.h5\",\n",
    "    'RESAMPLING': {'apply': True, 'resolution': (1.0, 1.0, 1.0)},\n",
    "    'LABELS': [\"common_carotid_artery_left\"],\n",
    "    'LABEL_GROUPS': None, \n",
    "    'DATASET_DESCRIPTION': {\n",
    "        'id': 1,\n",
    "        'name': 'NeckCTA',\n",
    "        'description': 'Neck CTA dataset',\n",
    "        'reference': 'HMH'\n",
    "    },\n",
    "    'TEST_SET_SIZE': 2,\n",
    "    'LEAVE_OUT': None,\n",
    "    'INPUT_MODALITIES': ['ct'],\n",
    "    'OUTPUT_MODALITIES': ['rtstruct']}\n",
    "\n",
    "class Preprocessing(DicomTools):\n",
    "    \n",
    "    '''\n",
    "        Created by Ivan Vazquez in collaboration with Ramiro Pino\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        self.__start_logger()\n",
    "        self.params = params\n",
    "        super().__init__(patient_data_directory=params['DATA_DIRECTORY'])\n",
    "        self.expected_data = params['INPUT_MODALITIES'] + params['OUTPUT_MODALITIES']\n",
    "        self.labels = params['LABELS']\n",
    "        self.echo_level = 0\n",
    "        self.minimum_ct_value = -1024\n",
    "        self.uniform_slice_thickness = False # forces uniform slice thickness for CT during parsing\n",
    "        self.preprocessed_data_dir = params['PREPROCESSED_DATA_DIRECTORY']\n",
    "        self.raw_data_dir = os.getenv('nnUNet_raw') # assumet that nnUNet environment variable is set and defined as nnUNet_raw\n",
    "        self.preprocessed_data_fldr = os.getenv('nnUNet_preprocessed') \n",
    "        self.__data_id = f'Dataset{params[\"DATASET_DESCRIPTION\"][\"id\"]:03}_{params[\"DATASET_DESCRIPTION\"][\"name\"]}'\n",
    "        \n",
    "    def __start_logger(self):\n",
    "        if not os.path.exists('logs'):\n",
    "            os.makedirs('logs')\n",
    "        log_file = os.path.join('logs','data_preparation.log')\n",
    "        with open(log_file, 'w') as f:\n",
    "            pass\n",
    "        logging.basicConfig(filename=log_file, filemode='w',\n",
    "                            level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "        \n",
    "    def get_data_insight(self):\n",
    "        all_pat_ids = self.identify_patient_files()\n",
    "        self.data_insight = {p:{} for p in all_pat_ids}\n",
    "        \n",
    "        progress_bar = tqdm(all_pat_ids, desc=\"\")\n",
    "        \n",
    "        for p in progress_bar:\n",
    "            \n",
    "            try:\n",
    "                progress_bar.set_description(f'Getting data insight for pat-{p}')\n",
    "                \n",
    "                self.reset()\n",
    "                \n",
    "                self.run_initial_check(p)\n",
    "                \n",
    "                # Handle input modalities\n",
    "                self.data_insight[p]['input_modalities'] = {m:0 for m in self.params['INPUT_MODALITIES']}\n",
    "                                \n",
    "                for i in self.params['INPUT_MODALITIES']:\n",
    "                    if i == 'ct' and 'ct' in self.dicom_files:\n",
    "                        self.ct = self.parse_ct_study_files(self.dicom_files['ct'])\n",
    "                        self.data_insight[p]['input_modalities']['ct']={'shape': [i for i in self.ct.data.shape], \n",
    "                                                                        'min': self.ct.data.min(),\n",
    "                                                                        'max': self.ct.data.max(),\n",
    "                                                                        'dx': self.ct.coordinates.dx,\n",
    "                                                                        'dy': self.ct.coordinates.dy,\n",
    "                                                                        'dz': [i for i in self.ct.coordinates.dz],\n",
    "                                                                        'position':self.ct.patient_position}\n",
    "                    elif i == 'ct' and 'ct' not in self.dicom_files:\n",
    "                        logging.warning(f\"CT not available for patient {p}\")\n",
    "                        self.data_insight[p]['input_modalities']['ct'] = 'CT not available'\n",
    "                    \n",
    "                # Handle output labels (structures)     \n",
    "                self.contours = self.parse_structure_files(files=self.dicom_files['structures'], names_only=True)\n",
    "                self.data_insight[p]['labels'] = self.find_structures(p, contours = self.labels)\n",
    "                self.data_insight[p]['number_of_structures'] = len(self.contours)\n",
    "                self.data_insight[p]['structures_available'] = sorted([c for c in self.contours])\n",
    "                \n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error in patient {p}: {e}\")\n",
    "                self.data_insight[p]['error'] = str(e)\n",
    "                    \n",
    "        with open(os.path.join(self.raw_data_dir,f'data_insight_{self.__data_id}.json'), 'w') as f:\n",
    "            json.dump(self.data_insight, f, indent=4)\n",
    "    \n",
    "    def find_structures(self, pat_id, contours = [], desperate_mode = True):\n",
    "                      \n",
    "        # prepare dictionary with desired contours\n",
    "        assert type(contours) == type([]) or type(contours) == type(()), \"Contours must be a list or tuple\"\n",
    "        contours = {c:0 for c in self.labels} if contours == [] else {c:0 for c in contours}\n",
    "                \n",
    "        # Load the variations for contour names\n",
    "        with open(os.path.join(\"assets\", \"structure_name_variations.json\"),\"r\") as f:\n",
    "            contour_variations = json.load(f)\n",
    "        \n",
    "        # items added to the name of contours that make it difficult to identify them\n",
    "        with open(os.path.join(\"assets\", \"junk_symbols.json\"),\"r\") as f:\n",
    "            junk_symbols = json.load(f)['oar']\n",
    "\n",
    "        # Grab available contours for current patients\n",
    "        if hasattr(self, 'contours'):\n",
    "            available_contours = self.contours if type(self.contours) == type([]) else self.contour.keys() \n",
    "        else:\n",
    "            self.run_initial_check(pat_id)\n",
    "            self.parse_structure_files(names_only = True)\n",
    "            available_contours = self.contours\n",
    "        \n",
    "        lr_variations = contour_variations[\"sides\"] # variations for left and right\n",
    "        links = ['_','-',\" \",\"\"] # types of links used for word elements in contour names\n",
    "                \n",
    "        for c in contours:  \n",
    "\n",
    "            side = lr_variations[\"left\"]  if \"left\" in c else lr_variations[\"right\"]  if \"right\" in c else [\"\"]\n",
    "            gland = contour_variations[\"gland\"] + [\"\"] if 'gland' in c else [\"\"] \n",
    "            links2 = links if 'gland' in c else [\"\"] # links to attach gland to name \n",
    "            k = '_'.join([kk for kk in c.split('_') if kk not in ['left', 'right', 'gland']]) \n",
    "              \n",
    "            # generate name variations\n",
    "            name_variations = [f\"{n}{l1}{g}{l2}{s}\" for n in contour_variations[k] for l1 in links for l2 in links2 for s in side for g in gland]\n",
    "            name_variations += [f\"{g}{l1}{n}{l2}{s}\" for n in contour_variations[k] for l1 in links for l2 in links2 for s in side for g in gland]\n",
    "            name_variations += [f\"{s}{l1}{n}{l2}{g}\" for n in contour_variations[k] for l1 in links for l2 in links2 for s in side for g in gland]\n",
    "            name_variations += [f\"{s}{l1}{g}{l2}{n}\" for n in contour_variations[k] for l1 in links for l2 in links2 for s in side for g in gland]\n",
    "                            \n",
    "            for v in name_variations:\n",
    "\n",
    "                if contours[c] != 0: break\n",
    "\n",
    "                for n in available_contours:\n",
    "                    if n == v: contours[c] = n.strip()\n",
    "\n",
    "                for n in available_contours:\n",
    "                    if contours[c] == 0:\n",
    "                        n_new = \"\".join([i for i in n if not i.isdigit()])\n",
    "                        if n_new.strip() == v: contours[c] = n.strip()\n",
    "\n",
    "                for n in available_contours:\n",
    "                    if contours[c] == 0:\n",
    "                        n_new = \"\".join([i for i in n.strip() if i not in ['_','/','.','-']])\n",
    "                        n_new = \"\".join([i for i in n_new if not i.isdigit()])\n",
    "                        if n_new.strip() == v: contours[c]= n.strip()\n",
    "                        \n",
    "                for n in available_contours:\n",
    "                    if desperate_mode and contours[c] == 0:\n",
    "                        for item in junk_symbols:\n",
    "                            n_new = n.strip().replace(item,\"\")\n",
    "                            n_new = \"\".join([i for i in n_new.strip() if i not in ['_','/','.','-']])\n",
    "                            n_new = \"\".join([i for i in n_new if not i.isdigit()])\n",
    "                            if n_new.strip() == v: contours[c] = n.strip()    \n",
    "                               \n",
    "        return contours\n",
    "    \n",
    "    def prepare_data(self, data_insight_file_path= None):\n",
    "        \n",
    "        self.prepare_dataset_folders()\n",
    "        \n",
    "        if data_insight_file_path is not None:\n",
    "            self.data_insight = json.load(open(data_insight_file_path, 'r'))\n",
    "        else:\n",
    "            self.get_data_insight()\n",
    "            \n",
    "        parent_dir = os.path.join(self.preprocessed_data_fldr, 'preprocessed_hdf5_files')\n",
    "        if not os.path.exists(parent_dir): os.makedirs(parent_dir)\n",
    "            \n",
    "        if self.preprocessed_data_dir is not None and os.path.exists(self.preprocessed_data_dir):\n",
    "            preprocess_data = False\n",
    "        elif self.preprocessed_data_dir is not None and not os.path.exists(self.preprocessed_data_dir):\n",
    "            preprocess_data = True\n",
    "            logging.warning(f\"Preprocessed data file not found at {self.preprocessed_data_dir}.\"  + \n",
    "                            \"Will create new preprocessed data file\")\n",
    "            self.preprocessed_data_dir = os.path.join(parent_dir, f'preprocessed_{self.__data_id}.h5')\n",
    "        elif self.preprocessed_data_dir is None:\n",
    "            preprocess_data = True\n",
    "            self.preprocessed_data_dir = os.path.join(parent_dir, f'preprocessed_{self.__data_id}.h5')\n",
    "    \n",
    "        if preprocess_data:\n",
    "                                \n",
    "            with h5py.File(self.preprocessed_data_dir, 'w') as f:\n",
    "                \n",
    "                progress_bar = tqdm([p for p in self.data_insight], desc=\"\")\n",
    "                \n",
    "                for p in progress_bar:\n",
    "                    \n",
    "                    progress_bar.set_description(f'Preprocessing data for pat-{p}')\n",
    "                    \n",
    "                    patient_info = self.data_insight[p]\n",
    "                    if 'error' in patient_info: continue \n",
    "                    if not all([patient_info['labels'][l] for l in patient_info['labels']]): continue\n",
    "                                    \n",
    "                    self.reset()\n",
    "                    self.run_initial_check(p)  \n",
    "                    \n",
    "                    for i in self.params['INPUT_MODALITIES']:\n",
    "                        \n",
    "                        files = self.dicom_files[i]\n",
    "                        \n",
    "                        if i == 'ct':\n",
    "                            mod = self.parse_ct_study_files(files)\n",
    "                            \n",
    "                        # TODO: addapt to other modalities \n",
    "                                            \n",
    "                        # resample data here\n",
    "                        orig_coords = copy.deepcopy(mod.coordinates) \n",
    "                        new_res = self.params['RESAMPLING']['resolution']\n",
    "                        \n",
    "                        mod_data, coords = resize_to_user_resolution(mod.data, orig_coords, new_res, fill_value=mod.data.min()) if self.params['RESAMPLING']['apply'] else (mod.data, orig_coords)\n",
    "                    \n",
    "                        f.create_dataset(f'{p}/modalities/{i}', data=mod_data, compression='lzf')\n",
    "                        f.create_dataset(f'{p}/coordinates/x', data=coords.x)\n",
    "                        f.create_dataset(f'{p}/coordinates/y', data=coords.y)\n",
    "                        f.create_dataset(f'{p}/coordinates/z', data=coords.z)\n",
    "                        f.create_dataset(f'{p}/coordinates/dx', data=coords.dx)\n",
    "                        f.create_dataset(f'{p}/coordinates/dy', data=coords.dy)\n",
    "                        f.create_dataset(f'{p}/coordinates/dz', data=coords.dz)\n",
    "                                \n",
    "                    for label in self.labels:\n",
    "                        contour_name = patient_info['labels'][label]\n",
    "                        contour = self.parse_structure_files(files=sorted(self.dicom_files['structures']), patient_id=p, mask_names=contour_name, resolution='ct')\n",
    "                        mask, _ = resize_to_user_resolution(contour[contour_name].data, orig_coords, new_res, fill_value=0) if self.params['RESAMPLING']['apply'] else (contour[label].data, None)\n",
    "                        f.create_dataset(f'{p}/labels/{label}', data=np.round(mask).astype(np.uint8))\n",
    "        \n",
    "        self.create_data_breakdowns(self.preprocessed_data_dir)\n",
    "                        \n",
    "    def save_as_nifti(self, volume, voxel_spacing, output_path, **kwargs):\n",
    "        \n",
    "        # grab header information from kwargs\n",
    "        modality = kwargs.get('modality', 'CT')\n",
    "        \n",
    "        # header = nifti_img.header\n",
    "\n",
    "        if not isinstance(voxel_spacing, (list, tuple)) or len(voxel_spacing) != 3:\n",
    "            raise ValueError(\"voxel_spacing must be a list or tuple with 3 elements.\")\n",
    "\n",
    "        affine = np.eye(4)\n",
    "        affine[0, 0] = voxel_spacing[0]  # Spacing in x\n",
    "        affine[1, 1] = voxel_spacing[1]  # Spacing in y\n",
    "        affine[2, 2] = voxel_spacing[2]  # Spacing in z\n",
    "\n",
    "        nifti_image = nib.Nifti1Image(volume, affine=affine)\n",
    "        \n",
    "        header = nifti_image.header\n",
    "        header.set_xyzt_units('mm', 'sec')\n",
    "        header['qform_code'] = 1\n",
    "        header['descrip'] = modality\n",
    "        header['pixdim'] = np.array([1.0, voxel_spacing[0], voxel_spacing[1], voxel_spacing[2], 1.0, 1.0, 1.0, 1.0])\n",
    "        \n",
    "        nib.save(nifti_image, output_path)       \n",
    "    \n",
    "    def prepare_dataset_folders(self):\n",
    "        \n",
    "        self.dataset_path = os.path.join(self.raw_data_dir, self.__data_id) # depends on the nnUNet environment variable\n",
    "        if os.path.exists(self.dataset_path ): shutil.rmtree(self.dataset_path )\n",
    "        os.makedirs(self.dataset_path , exist_ok=True)  \n",
    "        \n",
    "        for dir_name in ['imagesTr', 'imagesTs', 'labelsTr', 'labelsTs']:\n",
    "            os.makedirs(os.path.join(self.dataset_path , dir_name), exist_ok=True)\n",
    "    \n",
    "    def create_data_breakdowns(self, data_path):\n",
    "        \n",
    "        with h5py.File(data_path, 'r') as f:\n",
    "            all_data_ids = list(f.keys())\n",
    "        \n",
    "        if self.params['LEAVE_OUT'] is not None: all_data_ids = [int(pat) for pat in all_data_ids if int(pat) not in self.params['LEAVE_OUT']]\n",
    "\n",
    "        self.test_set = random.sample(all_data_ids, self.params['TEST_SET_SIZE'])\n",
    "        self.train_set = [n for n in all_data_ids if n not in self.test_set]\n",
    "        \n",
    "        if self.params['LABEL_GROUPS'] is None:\n",
    "            label_groups = {k:{'labels':[k], 'id':n+1} for n,k in enumerate(self.labels)}\n",
    "        else:\n",
    "            label_groups = self.params['LABEL_GROUPS']\n",
    "            label_groups = {k:{'labels':[l for l in v], 'id':n+1} for n,(k,v) in enumerate(label_groups.items())}\n",
    "                            \n",
    "        with h5py.File(data_path, 'r') as hf:\n",
    "            \n",
    "            self.__save_data(hf, 'Tr', label_groups)\n",
    "        \n",
    "            self.__save_data(hf, 'Ts', label_groups)  \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # output_dir = '../raw_data/Dataset001_NeckCTA'\n",
    "        # channel_names = {0: 'CT'}\n",
    "        # labels = {'common_carotid_artery_left': 1,\n",
    "        #         'background': 0}\n",
    "        # num_training_cases = len(os.listdir(os.path.join(output_dir, 'imagesTr')))\n",
    "        # print(num_training_cases)\n",
    "        # file_extension = '.nii.gz'\n",
    "        \n",
    "        self.generate_dataset_json(file_ending=\".nii.gz\")\n",
    "        \n",
    "        \n",
    "            \n",
    "        # self.dataset_path\n",
    "    \n",
    "    def generate_dataset_json(self, \n",
    "                              labels: dict,\n",
    "                              num_training_cases: int,\n",
    "                              file_ending: str,\n",
    "                              regions_class_order: Tuple[int, ...] = None,\n",
    "                              dataset_name: str = None, reference: str = None, release: str = None, license: str = None,\n",
    "                              description: str = None,\n",
    "                              overwrite_image_reader_writer: str = None, **kwargs):\n",
    "\n",
    "        has_regions: bool = any([isinstance(i, (tuple, list)) and len(i) > 1 for i in labels.values()])\n",
    "        if has_regions:\n",
    "            assert regions_class_order is not None, f\"You have defined regions but regions_class_order is not set. \" \\\n",
    "                                                    f\"You need that.\"\n",
    "        \n",
    "        # prepare labels using label groups \n",
    "        # labels = {'background':0}\n",
    "        \n",
    "        \n",
    "        # channel names need strings as keys\n",
    "        channel_names = {k:n for k,n in enumerate(self.param[\"INPUT_MODALITIES\"])}\n",
    "        \n",
    "        print(channel_names)\n",
    "        \n",
    "        keys = channel_names.keys()\n",
    "        for k in keys:\n",
    "            if not isinstance(k, str):\n",
    "                channel_names[str(k)] = channel_names[k]\n",
    "                del channel_names[k]\n",
    "\n",
    "        # TODO: create a list with the labels and corresponding id values \n",
    "\n",
    "        # labels need ints as values\n",
    "        for l in labels.keys():\n",
    "            value = labels[l]\n",
    "            if isinstance(value, (tuple, list)):\n",
    "                value = tuple([int(i) for i in value])\n",
    "                labels[l] = value\n",
    "            else:\n",
    "                labels[l] = int(labels[l])\n",
    "\n",
    "        dataset_json = {\n",
    "            'channel_names': channel_names, \n",
    "            'labels': labels,\n",
    "            'numTraining': num_training_cases,\n",
    "            'file_ending': file_ending,\n",
    "        }\n",
    "\n",
    "        if dataset_name is not None:\n",
    "            dataset_json['name'] = dataset_name\n",
    "        if reference is not None:\n",
    "            dataset_json['reference'] = reference\n",
    "        if release is not None:\n",
    "            dataset_json['release'] = release\n",
    "        if license is not None:\n",
    "            dataset_json['licence'] = license\n",
    "        if description is not None:\n",
    "            dataset_json['description'] = description\n",
    "        if overwrite_image_reader_writer is not None:\n",
    "            dataset_json['overwrite_image_reader_writer'] = overwrite_image_reader_writer\n",
    "        if regions_class_order is not None:\n",
    "            dataset_json['regions_class_order'] = regions_class_order\n",
    "\n",
    "        dataset_json.update(kwargs)\n",
    "\n",
    "        save_json(dataset_json, join(self.dataset_path, 'dataset.json'), sort_keys=False)\n",
    "                \n",
    "    def __save_data(self, hf, data_type, label_groups):\n",
    "        \n",
    "        data_set = self.train_set if data_type == 'Tr' else self.test_set\n",
    "        pb_desc = \"Saving training data\" if data_type == 'Tr' else \"Saving test data\"\n",
    "        \n",
    "        progress_bar = tqdm(data_set, desc=pb_desc)\n",
    "                \n",
    "        for pat in progress_bar:\n",
    "            \n",
    "            for m, modality in enumerate(self.params['INPUT_MODALITIES']):\n",
    "                \n",
    "                mod_data = hf[f'{pat}/modalities/{modality}'][:]\n",
    "                voxel_spacing = [hf[f'{pat}/coordinates/dx'][()], hf[f'{pat}/coordinates/dy'][()], hf[f'{pat}/coordinates/dz'][()]]\n",
    "                output_path = os.path.join(self.dataset_path, f'images{data_type}',  f\"{data_type}Dat{int(pat):03d}_{m:04d}.nii.gz\")\n",
    "                self.save_as_nifti( np.transpose(mod_data, (2, 1, 0)), voxel_spacing,  output_path, modality=modality)\n",
    "            \n",
    "            label_data = np.zeros(mod_data.shape)\n",
    "                            \n",
    "            for lg in label_groups:\n",
    "                for l in label_groups[lg]['labels']:\n",
    "                    label_data[np.where(hf[f'{pat}/labels/{l}'][:]>0)] = label_groups[lg]['id']\n",
    "            output_path = os.path.join(self.dataset_path, f'labels{data_type}',  f\"{data_type}Dat{int(pat):03d}.nii.gz\")\n",
    "            self.save_as_nifti(np.transpose(label_data, (2, 1, 0)).astype(np.uint8), voxel_spacing, output_path, modality='RTSTRUCT')\n",
    "            \n",
    "dp = Preprocessing(params)\n",
    "dp.prepare_data()#data_insight_file_path = \"/home/ivazquez/Repos/nnUNet/raw_data/data_insight_Dataset001_NeckCTA.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "from batchgenerators.utilities.file_and_folder_operations import save_json, join\n",
    "\n",
    "output_dir = '../raw_data/Dataset001_NeckCTA'\n",
    "channel_names = {0: 'CT'}\n",
    "labels = {'common_carotid_artery_left': 1,\n",
    "          'background': 0}\n",
    "num_training_cases = len(os.listdir(os.path.join(output_dir, 'imagesTr')))\n",
    "print(num_training_cases)\n",
    "file_extension = '.nii.gz'\n",
    "\n",
    "def generate_dataset_json(output_folder: str,\n",
    "                          channel_names: dict,\n",
    "                          labels: dict,\n",
    "                          num_training_cases: int,\n",
    "                          file_ending: str,\n",
    "                          regions_class_order: Tuple[int, ...] = None,\n",
    "                          dataset_name: str = None, reference: str = None, release: str = None, license: str = None,\n",
    "                          description: str = None,\n",
    "                          overwrite_image_reader_writer: str = None, **kwargs):\n",
    "    \"\"\"\n",
    "    Generates a dataset.json file in the output folder\n",
    "\n",
    "    channel_names:\n",
    "        Channel names must map the index to the name of the channel, example:\n",
    "        {\n",
    "            0: 'T1',\n",
    "            1: 'CT'\n",
    "        }\n",
    "        Note that the channel names may influence the normalization scheme!! Learn more in the documentation.\n",
    "\n",
    "    labels:\n",
    "        This will tell nnU-Net what labels to expect. Important: This will also determine whether you use region-based training or not.\n",
    "        Example regular labels:\n",
    "        {\n",
    "            'background': 0,\n",
    "            'left atrium': 1,\n",
    "            'some other label': 2\n",
    "        }\n",
    "        Example region-based training:\n",
    "        {\n",
    "            'background': 0,\n",
    "            'whole tumor': (1, 2, 3),\n",
    "            'tumor core': (2, 3),\n",
    "            'enhancing tumor': 3\n",
    "        }\n",
    "\n",
    "        Remember that nnU-Net expects consecutive values for labels! nnU-Net also expects 0 to be background!\n",
    "\n",
    "    num_training_cases: is used to double check all cases are there!\n",
    "\n",
    "    file_ending: needed for finding the files correctly. IMPORTANT! File endings must match between images and\n",
    "    segmentations!\n",
    "\n",
    "    dataset_name, reference, release, license, description: self-explanatory and not used by nnU-Net. Just for\n",
    "    completeness and as a reminder that these would be great!\n",
    "\n",
    "    overwrite_image_reader_writer: If you need a special IO class for your dataset you can derive it from\n",
    "    BaseReaderWriter, place it into nnunet.imageio and reference it here by name\n",
    "\n",
    "    kwargs: whatever you put here will be placed in the dataset.json as well\n",
    "\n",
    "    \"\"\"\n",
    "    has_regions: bool = any([isinstance(i, (tuple, list)) and len(i) > 1 for i in labels.values()])\n",
    "    if has_regions:\n",
    "        assert regions_class_order is not None, f\"You have defined regions but regions_class_order is not set. \" \\\n",
    "                                                f\"You need that.\"\n",
    "    # channel names need strings as keys\n",
    "    keys = list(channel_names.keys())\n",
    "    for k in keys:\n",
    "        if not isinstance(k, str):\n",
    "            channel_names[str(k)] = channel_names[k]\n",
    "            del channel_names[k]\n",
    "\n",
    "    # labels need ints as values\n",
    "    for l in labels.keys():\n",
    "        value = labels[l]\n",
    "        if isinstance(value, (tuple, list)):\n",
    "            value = tuple([int(i) for i in value])\n",
    "            labels[l] = value\n",
    "        else:\n",
    "            labels[l] = int(labels[l])\n",
    "\n",
    "    dataset_json = {\n",
    "        'channel_names': channel_names,  # previously this was called 'modality'. I didn't like this so this is\n",
    "        # channel_names now. Live with it.\n",
    "        'labels': labels,\n",
    "        'numTraining': num_training_cases,\n",
    "        'file_ending': file_ending,\n",
    "    }\n",
    "\n",
    "    if dataset_name is not None:\n",
    "        dataset_json['name'] = dataset_name\n",
    "    if reference is not None:\n",
    "        dataset_json['reference'] = reference\n",
    "    if release is not None:\n",
    "        dataset_json['release'] = release\n",
    "    if license is not None:\n",
    "        dataset_json['licence'] = license\n",
    "    if description is not None:\n",
    "        dataset_json['description'] = description\n",
    "    if overwrite_image_reader_writer is not None:\n",
    "        dataset_json['overwrite_image_reader_writer'] = overwrite_image_reader_writer\n",
    "    if regions_class_order is not None:\n",
    "        dataset_json['regions_class_order'] = regions_class_order\n",
    "\n",
    "    dataset_json.update(kwargs)\n",
    "\n",
    "    save_json(dataset_json, join(output_folder, 'dataset.json'), sort_keys=False)\n",
    "    print('here')\n",
    "    \n",
    "generate_dataset_json(output_dir, channel_names, labels, num_training_cases, file_extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File('../raw_data/preprocessed_hdf5_files/preprocessed_Dataset001_NeckCTA.h5', 'r') as f:\n",
    "    print(f.keys())\n",
    "    print(f['1'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scheme introduced above results in the following folder structure. Given is an example for the first Dataset of the MSD: BrainTumour. This dataset hat four input channels: FLAIR (0000), T1w (0001), T1gd (0002) and T2w (0003). Note that the imagesTs folder is optional and does not have to be present.\n",
    "\n",
    "```\n",
    "nnUNet_raw/Dataset001_BrainTumour/\n",
    "├── dataset.json\n",
    "├── imagesTr\n",
    "│   ├── BRATS_001_0000.nii.gz\n",
    "│   ├── BRATS_001_0001.nii.gz\n",
    "│   ├── BRATS_001_0002.nii.gz\n",
    "│   ├── BRATS_001_0003.nii.gz\n",
    "│   ├── BRATS_002_0000.nii.gz\n",
    "│   ├── BRATS_002_0001.nii.gz\n",
    "│   ├── BRATS_002_0002.nii.gz\n",
    "│   ├── BRATS_002_0003.nii.gz\n",
    "│   ├── ...\n",
    "├── imagesTs\n",
    "│   ├── BRATS_485_0000.nii.gz\n",
    "│   ├── BRATS_485_0001.nii.gz\n",
    "│   ├── BRATS_485_0002.nii.gz\n",
    "│   ├── BRATS_485_0003.nii.gz\n",
    "│   ├── BRATS_486_0000.nii.gz\n",
    "│   ├── BRATS_486_0001.nii.gz\n",
    "│   ├── BRATS_486_0002.nii.gz\n",
    "│   ├── BRATS_486_0003.nii.gz\n",
    "│   ├── ...\n",
    "└── labelsTr\n",
    "    ├── BRATS_001.nii.gz\n",
    "    ├── BRATS_002.nii.gz\n",
    "    ├── ...\n",
    "```\n",
    "\n",
    "Example of data arrangement\n",
    "\n",
    "```\n",
    "nnUNet_raw/Dataset002_Heart/\n",
    "├── dataset.json\n",
    "├── imagesTr\n",
    "│   ├── la_003_0000.nii.gz\n",
    "│   ├── la_004_0000.nii.gz\n",
    "│   ├── ...\n",
    "├── imagesTs\n",
    "│   ├── la_001_0000.nii.gz\n",
    "│   ├── la_002_0000.nii.gz\n",
    "│   ├── ...\n",
    "└── labelsTr\n",
    "    ├── la_003.nii.gz\n",
    "    ├── la_004.nii.gz\n",
    "    ├── ...\n",
    "```\n",
    "\n",
    "\n",
    "```json\n",
    "{ \n",
    " \"channel_names\": {  # formerly modalities\n",
    "   \"0\": \"T2\", \n",
    "   \"1\": \"ADC\"\n",
    " }, \n",
    " \"labels\": {  # THIS IS DIFFERENT NOW!\n",
    "   \"background\": 0,\n",
    "   \"PZ\": 1,\n",
    "   \"TZ\": 2\n",
    " }, \n",
    " \"numTraining\": 32, \n",
    " \"file_ending\": \".nii.gz\"\n",
    " \"overwrite_image_reader_writer\": \"SimpleITKIO\"  # optional! If not provided nnU-Net will automatically determine the ReaderWriter\n",
    " }\n",
    " ```\n",
    " The channel_names determine the normalization used by nnU-Net. If a channel is marked as 'CT', then a global normalization based on the intensities in the foreground pixels will be used. If it is something else, per-channel z-scoring will be used. Refer to the methods section in our paper for more details. nnU-Net v2 introduces a few more normalization schemes to choose from and allows you to define your own, see here for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Function to display CT and contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAT_ID = 3\n",
    "# DATA_DIRECTORY = \"/home/ivazquez/Repos/nnUNet/raw_data/neck_cta/anonymized\"\n",
    "WINDOW_WIDTH = 400 # HU\n",
    "WINDOW_CENTER = 40 # HU\n",
    "INITIAL_SLICE = None\n",
    "COLORMAP = 'gray'\n",
    "\n",
    "dt = DicomToolbox(patient_data_directory = DATA_DIRECTORY)\n",
    "dt.expected_data = ['ct', 'rtstruct']\n",
    "dt.uniform_slice_thickness = False\n",
    "dt.parse_dicom_files(PAT_ID, mask_resolution = 'ct', mask_names_only=False)\n",
    "\n",
    "ct = dt.ct.data # grab the ct data\n",
    "orig_coords = copy.deepcopy(dt.ct.coordinates) # grab the coordinates\n",
    "# ct, dt.ct.coordinates = resize_to_user_resolution(ct, dt.ct.coordinates, [1,1,1]) \n",
    "\n",
    "ct = apply_windowing(ct, WINDOW_WIDTH, WINDOW_CENTER) # apply windowing\n",
    "structures = [c for c in dt.contours]\n",
    "\n",
    "# Create a Select widget\n",
    "select_structures = Select(\n",
    "    options=structures,\n",
    "    value=structures[0],\n",
    "    description='Structures:',\n",
    "    rows=len(structures))\n",
    "\n",
    "display(HBox([select_structures]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, Listbox, Scrollbar\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import copy\n",
    "from dicom_tools import DicomToolbox  # Ensure this module is available\n",
    "\n",
    "class DicomViewer:\n",
    "    def __init__(self, root, data_directory, pat_id, window_width, window_center):\n",
    "        self.root = root\n",
    "        self.data_directory = data_directory\n",
    "        self.pat_id = pat_id\n",
    "        self.window_width = window_width\n",
    "        self.window_center = window_center\n",
    "\n",
    "        self.dt = DicomToolbox(patient_data_directory=data_directory)\n",
    "        self.dt.expected_data = ['ct', 'rtstruct']\n",
    "        self.dt.uniform_slice_thickness = False\n",
    "        self.dt.parse_dicom_files(pat_id, mask_resolution='ct', mask_names_only=False)\n",
    "\n",
    "        self.ct = self.dt.ct.data\n",
    "        self.orig_coords = copy.deepcopy(self.dt.ct.coordinates)\n",
    "        self.ct = self.apply_windowing(self.ct, window_width, window_center)\n",
    "        self.structures = [c for c in self.dt.contours]\n",
    "\n",
    "        self.create_widgets()\n",
    "        self.update_plot()\n",
    "\n",
    "    def create_widgets(self):\n",
    "        self.structure_listbox = Listbox(self.root, selectmode=tk.SINGLE)\n",
    "        for struct in self.structures:\n",
    "            self.structure_listbox.insert(tk.END, struct)\n",
    "        self.structure_listbox.bind('<<ListboxSelect>>', lambda event: self.update_plot())\n",
    "        self.structure_listbox.pack(side=tk.LEFT, fill=tk.Y)\n",
    "\n",
    "        scrollbar = Scrollbar(self.root)\n",
    "        scrollbar.pack(side=tk.LEFT, fill=tk.Y)\n",
    "        self.structure_listbox.config(yscrollcommand=scrollbar.set)\n",
    "        scrollbar.config(command=self.structure_listbox.yview)\n",
    "\n",
    "        self.figure, self.ax = plt.subplots(figsize=(7, 7))\n",
    "        self.canvas = FigureCanvasTkAgg(self.figure, master=self.root)\n",
    "        self.canvas.get_tk_widget().pack()\n",
    "\n",
    "        self.slice_var = tk.IntVar(value=self.ct.shape[0] // 2)\n",
    "        self.slice_slider = ttk.Scale(self.root, from_=0, to=self.ct.shape[0] - 1, orient=\"horizontal\", variable=self.slice_var)\n",
    "        self.slice_slider.pack(fill=tk.X)\n",
    "        self.slice_slider.bind(\"<Motion>\", lambda event: self.update_plot())\n",
    "\n",
    "        self.root.bind('<Left>', self.previous_slice)\n",
    "        self.root.bind('<Right>', self.next_slice)\n",
    "\n",
    "    def apply_windowing(self, image, window_width, window_center):\n",
    "        min_hu = window_center - window_width // 2\n",
    "        max_hu = window_center + window_width // 2\n",
    "        image = np.clip(image, min_hu, max_hu)\n",
    "        image = (image - min_hu) / (max_hu - min_hu) * 255.0\n",
    "        return image\n",
    "\n",
    "    def update_plot(self, event=None):\n",
    "        slice_idx = self.slice_var.get()\n",
    "        selected_idx = self.structure_listbox.curselection()\n",
    "        if selected_idx:\n",
    "            structure_name = self.structure_listbox.get(selected_idx)\n",
    "            structure = self.dt.contours[structure_name].data\n",
    "\n",
    "            self.ax.clear()\n",
    "            ct_extent = [self.dt.ct.coordinates.x.min(), self.dt.ct.coordinates.x.max(),\n",
    "                         self.dt.ct.coordinates.y.max(), self.dt.ct.coordinates.y.min()]\n",
    "            self.ax.imshow(self.ct[slice_idx], cmap='gray', interpolation='none', extent=ct_extent)\n",
    "            x, y = self.dt.ct.coordinates.x, self.dt.ct.coordinates.y\n",
    "            self.ax.contour(x, y, structure[slice_idx], levels=[0.5], colors='red')\n",
    "            self.ax.axis('off')\n",
    "\n",
    "            self.canvas.draw()\n",
    "\n",
    "    def previous_slice(self, event):\n",
    "        current_slice = self.slice_var.get()\n",
    "        if current_slice > 0:\n",
    "            self.slice_var.set(current_slice - 1)\n",
    "            self.update_plot()\n",
    "\n",
    "    def next_slice(self, event):\n",
    "        current_slice = self.slice_var.get()\n",
    "        if current_slice < self.ct.shape[0] - 1:\n",
    "            self.slice_var.set(current_slice + 1)\n",
    "            self.update_plot()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    root.title(\"DICOM Viewer\")\n",
    "\n",
    "    data_directory = \"/home/ivazquez/Documents/REPOS/nnUNet/raw_data/neck_cta/anonymized\"\n",
    "    pat_id = 1\n",
    "    window_width = 400\n",
    "    window_center = 40\n",
    "\n",
    "    viewer = DicomViewer(root, data_directory, pat_id, window_width, window_center)\n",
    "    root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
